{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a3d493-83fb-4965-bdcb-f1054425e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geojson\n",
      "  Downloading geojson-3.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Downloading geojson-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: geojson\n",
      "Successfully installed geojson-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Downloading shapely-2.1.2-cp311-cp311-win_amd64.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\422mi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shapely) (2.2.6)\n",
      "Downloading shapely-2.1.2-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 47.1 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely\n",
      "Successfully installed shapely-2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyShp\n",
      "  Downloading pyshp-3.0.2.post1-py3-none-any.whl.metadata (64 kB)\n",
      "Downloading pyshp-3.0.2.post1-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: PyShp\n",
      "Successfully installed PyShp-3.0.2.post1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\422mi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dbfread\n",
      "  Downloading dbfread-2.0.7-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading dbfread-2.0.7-py2.py3-none-any.whl (20 kB)\n",
      "Installing collected packages: dbfread\n",
      "Successfully installed dbfread-2.0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install geojson\n",
    "!pip install shapely\n",
    "!pip install PyShp\n",
    "!pip install networkx\n",
    "!pip install dbfread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a7f250-1f24-4f02-832b-1df2dceaa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Polygon,shape,MultiPolygon\n",
    "import shapely.ops\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959227a9-93f8-47fa-87ef-02037facafb9",
   "metadata": {},
   "source": [
    "# We will work on New Hampshire\n",
    "The data is in Canvas, you should upload it to your Google Drive first (if using Colab), or local filesystem (if using Jupyter).\n",
    "The NJ data is formatted the same way, just replace 'nh' with 'nj'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69143d08-629d-436a-8687-7a5d3bcb5aa3",
   "metadata": {},
   "source": [
    "### This is the current assignment of precinct to congressional districts (2 of them for NH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0c2b03-9b2f-46c5-b619-0709ca555c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>Total_2016-2021_Comp</th>\n",
       "      <th>Dem_2016-2021_Comp</th>\n",
       "      <th>Rep_2016-2021_Comp</th>\n",
       "      <th>Total_2021_Gov</th>\n",
       "      <th>Dem_2021_Gov</th>\n",
       "      <th>Rep_2021_Gov</th>\n",
       "      <th>Total_2020_Sen</th>\n",
       "      <th>Dem_2020_Sen</th>\n",
       "      <th>Rep_2020_Sen</th>\n",
       "      <th>...</th>\n",
       "      <th>Native_2020_VAP</th>\n",
       "      <th>Pacific_2020_VAP</th>\n",
       "      <th>Total_2020_TotalAdj</th>\n",
       "      <th>White_2020_TotalAdj</th>\n",
       "      <th>Hispanic_2020_TotalAdj</th>\n",
       "      <th>Black_2020_TotalAdj</th>\n",
       "      <th>Asian_2020_TotalAdj</th>\n",
       "      <th>Native_2020_TotalAdj</th>\n",
       "      <th>Pacific_2020_TotalAdj</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34001005101</td>\n",
       "      <td>684</td>\n",
       "      <td>272</td>\n",
       "      <td>401</td>\n",
       "      <td>547</td>\n",
       "      <td>175</td>\n",
       "      <td>368</td>\n",
       "      <td>857</td>\n",
       "      <td>394</td>\n",
       "      <td>452</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1241</td>\n",
       "      <td>946</td>\n",
       "      <td>128</td>\n",
       "      <td>105</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34001005102</td>\n",
       "      <td>657</td>\n",
       "      <td>327</td>\n",
       "      <td>318</td>\n",
       "      <td>531</td>\n",
       "      <td>248</td>\n",
       "      <td>279</td>\n",
       "      <td>840</td>\n",
       "      <td>452</td>\n",
       "      <td>372</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1915</td>\n",
       "      <td>1332</td>\n",
       "      <td>211</td>\n",
       "      <td>286</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34001005103</td>\n",
       "      <td>943</td>\n",
       "      <td>368</td>\n",
       "      <td>554</td>\n",
       "      <td>748</td>\n",
       "      <td>264</td>\n",
       "      <td>474</td>\n",
       "      <td>1181</td>\n",
       "      <td>519</td>\n",
       "      <td>644</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1764</td>\n",
       "      <td>1377</td>\n",
       "      <td>177</td>\n",
       "      <td>83</td>\n",
       "      <td>106</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34001005201</td>\n",
       "      <td>657</td>\n",
       "      <td>273</td>\n",
       "      <td>373</td>\n",
       "      <td>539</td>\n",
       "      <td>225</td>\n",
       "      <td>310</td>\n",
       "      <td>801</td>\n",
       "      <td>340</td>\n",
       "      <td>450</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1311</td>\n",
       "      <td>906</td>\n",
       "      <td>168</td>\n",
       "      <td>150</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34001005202</td>\n",
       "      <td>647</td>\n",
       "      <td>419</td>\n",
       "      <td>221</td>\n",
       "      <td>428</td>\n",
       "      <td>255</td>\n",
       "      <td>171</td>\n",
       "      <td>845</td>\n",
       "      <td>567</td>\n",
       "      <td>271</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1902</td>\n",
       "      <td>538</td>\n",
       "      <td>336</td>\n",
       "      <td>602</td>\n",
       "      <td>451</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>34041115002</td>\n",
       "      <td>490</td>\n",
       "      <td>144</td>\n",
       "      <td>338</td>\n",
       "      <td>396</td>\n",
       "      <td>132</td>\n",
       "      <td>259</td>\n",
       "      <td>594</td>\n",
       "      <td>176</td>\n",
       "      <td>408</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>737</td>\n",
       "      <td>714</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>34041115003</td>\n",
       "      <td>501</td>\n",
       "      <td>137</td>\n",
       "      <td>351</td>\n",
       "      <td>400</td>\n",
       "      <td>100</td>\n",
       "      <td>290</td>\n",
       "      <td>607</td>\n",
       "      <td>181</td>\n",
       "      <td>408</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>934</td>\n",
       "      <td>820</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>34041115004</td>\n",
       "      <td>383</td>\n",
       "      <td>113</td>\n",
       "      <td>259</td>\n",
       "      <td>311</td>\n",
       "      <td>82</td>\n",
       "      <td>223</td>\n",
       "      <td>474</td>\n",
       "      <td>155</td>\n",
       "      <td>300</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>697</td>\n",
       "      <td>602</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>34041115005</td>\n",
       "      <td>482</td>\n",
       "      <td>147</td>\n",
       "      <td>323</td>\n",
       "      <td>404</td>\n",
       "      <td>111</td>\n",
       "      <td>284</td>\n",
       "      <td>581</td>\n",
       "      <td>194</td>\n",
       "      <td>371</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>931</td>\n",
       "      <td>832</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>34041115006</td>\n",
       "      <td>390</td>\n",
       "      <td>99</td>\n",
       "      <td>277</td>\n",
       "      <td>338</td>\n",
       "      <td>72</td>\n",
       "      <td>254</td>\n",
       "      <td>461</td>\n",
       "      <td>133</td>\n",
       "      <td>311</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>778</td>\n",
       "      <td>700</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID20  Total_2016-2021_Comp  Dem_2016-2021_Comp  \\\n",
       "0     34001005101                   684                 272   \n",
       "1     34001005102                   657                 327   \n",
       "2     34001005103                   943                 368   \n",
       "3     34001005201                   657                 273   \n",
       "4     34001005202                   647                 419   \n",
       "...           ...                   ...                 ...   \n",
       "6356  34041115002                   490                 144   \n",
       "6357  34041115003                   501                 137   \n",
       "6358  34041115004                   383                 113   \n",
       "6359  34041115005                   482                 147   \n",
       "6360  34041115006                   390                  99   \n",
       "\n",
       "      Rep_2016-2021_Comp  Total_2021_Gov  Dem_2021_Gov  Rep_2021_Gov  \\\n",
       "0                    401             547           175           368   \n",
       "1                    318             531           248           279   \n",
       "2                    554             748           264           474   \n",
       "3                    373             539           225           310   \n",
       "4                    221             428           255           171   \n",
       "...                  ...             ...           ...           ...   \n",
       "6356                 338             396           132           259   \n",
       "6357                 351             400           100           290   \n",
       "6358                 259             311            82           223   \n",
       "6359                 323             404           111           284   \n",
       "6360                 277             338            72           254   \n",
       "\n",
       "      Total_2020_Sen  Dem_2020_Sen  Rep_2020_Sen  ...  Native_2020_VAP  \\\n",
       "0                857           394           452  ...               15   \n",
       "1                840           452           372  ...               30   \n",
       "2               1181           519           644  ...               13   \n",
       "3                801           340           450  ...               36   \n",
       "4                845           567           271  ...               17   \n",
       "...              ...           ...           ...  ...              ...   \n",
       "6356             594           176           408  ...                0   \n",
       "6357             607           181           408  ...                4   \n",
       "6358             474           155           300  ...                5   \n",
       "6359             581           194           371  ...                9   \n",
       "6360             461           133           311  ...                9   \n",
       "\n",
       "      Pacific_2020_VAP  Total_2020_TotalAdj  White_2020_TotalAdj  \\\n",
       "0                    0                 1241                  946   \n",
       "1                    4                 1915                 1332   \n",
       "2                    1                 1764                 1377   \n",
       "3                    3                 1311                  906   \n",
       "4                    1                 1902                  538   \n",
       "...                ...                  ...                  ...   \n",
       "6356                 0                  737                  714   \n",
       "6357                 0                  934                  820   \n",
       "6358                 0                  697                  602   \n",
       "6359                 0                  931                  832   \n",
       "6360                 0                  778                  700   \n",
       "\n",
       "      Hispanic_2020_TotalAdj  Black_2020_TotalAdj  Asian_2020_TotalAdj  \\\n",
       "0                        128                  105                   66   \n",
       "1                        211                  286                   84   \n",
       "2                        177                   83                  106   \n",
       "3                        168                  150                   64   \n",
       "4                        336                  602                  451   \n",
       "...                      ...                  ...                  ...   \n",
       "6356                      11                    3                    8   \n",
       "6357                      60                   26                   10   \n",
       "6358                      66                   16                    4   \n",
       "6359                      47                   27                   11   \n",
       "6360                      30                   27                    9   \n",
       "\n",
       "      Native_2020_TotalAdj  Pacific_2020_TotalAdj  District  \n",
       "0                       24                      0         2  \n",
       "1                       38                      4         2  \n",
       "2                       20                      2         2  \n",
       "3                       50                      5         2  \n",
       "4                       25                      1         2  \n",
       "...                    ...                    ...       ...  \n",
       "6356                     0                      0         7  \n",
       "6357                    14                      0         7  \n",
       "6358                     5                      0         7  \n",
       "6359                    12                      0         7  \n",
       "6360                    10                      0         7  \n",
       "\n",
       "[6361 rows x 117 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh_current_assignment = pd.read_csv('precinct-data-congress-nj.csv')\n",
    "nh_current_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bce06-2f20-4f82-959e-a95f91e25ba5",
   "metadata": {},
   "source": [
    "### This is the current demographic and voter data\n",
    "The data has a lot of attributes that lists voters of different demographics and parties in different elections. You can look at the data Dictionary on Canvas to get details. For this recitation we will only keep votes from the 2020  presidential election and the total 2020 population counts. You can use additional columns (e.g., Governor's elections results, voting age (VAP) population counts, or the composite Dem/Rep score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d13a23f-3b65-4852-a42d-3a87867f3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>District</th>\n",
       "      <th>Total_2020_Pres</th>\n",
       "      <th>Dem_2020_Pres</th>\n",
       "      <th>Rep_2020_Pres</th>\n",
       "      <th>Total_2020_Total</th>\n",
       "      <th>White_2020_Total</th>\n",
       "      <th>Hispanic_2020_Total</th>\n",
       "      <th>Black_2020_Total</th>\n",
       "      <th>Asian_2020_Total</th>\n",
       "      <th>Native_2020_Total</th>\n",
       "      <th>Pacific_2020_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34001005101</td>\n",
       "      <td>2</td>\n",
       "      <td>876</td>\n",
       "      <td>393</td>\n",
       "      <td>472</td>\n",
       "      <td>1240</td>\n",
       "      <td>946</td>\n",
       "      <td>128</td>\n",
       "      <td>102</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34001005102</td>\n",
       "      <td>2</td>\n",
       "      <td>852</td>\n",
       "      <td>450</td>\n",
       "      <td>388</td>\n",
       "      <td>1913</td>\n",
       "      <td>1331</td>\n",
       "      <td>211</td>\n",
       "      <td>286</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34001005103</td>\n",
       "      <td>2</td>\n",
       "      <td>1206</td>\n",
       "      <td>517</td>\n",
       "      <td>672</td>\n",
       "      <td>1760</td>\n",
       "      <td>1375</td>\n",
       "      <td>177</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34001005201</td>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>348</td>\n",
       "      <td>469</td>\n",
       "      <td>1311</td>\n",
       "      <td>906</td>\n",
       "      <td>168</td>\n",
       "      <td>150</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34001005202</td>\n",
       "      <td>2</td>\n",
       "      <td>868</td>\n",
       "      <td>579</td>\n",
       "      <td>282</td>\n",
       "      <td>1892</td>\n",
       "      <td>537</td>\n",
       "      <td>336</td>\n",
       "      <td>598</td>\n",
       "      <td>450</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>34041115002</td>\n",
       "      <td>7</td>\n",
       "      <td>606</td>\n",
       "      <td>182</td>\n",
       "      <td>418</td>\n",
       "      <td>737</td>\n",
       "      <td>714</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>34041115003</td>\n",
       "      <td>7</td>\n",
       "      <td>617</td>\n",
       "      <td>187</td>\n",
       "      <td>418</td>\n",
       "      <td>934</td>\n",
       "      <td>820</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>34041115004</td>\n",
       "      <td>7</td>\n",
       "      <td>478</td>\n",
       "      <td>160</td>\n",
       "      <td>308</td>\n",
       "      <td>697</td>\n",
       "      <td>602</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>34041115005</td>\n",
       "      <td>7</td>\n",
       "      <td>592</td>\n",
       "      <td>201</td>\n",
       "      <td>381</td>\n",
       "      <td>930</td>\n",
       "      <td>831</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>34041115006</td>\n",
       "      <td>7</td>\n",
       "      <td>464</td>\n",
       "      <td>138</td>\n",
       "      <td>319</td>\n",
       "      <td>777</td>\n",
       "      <td>699</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID20  District  Total_2020_Pres  Dem_2020_Pres  Rep_2020_Pres  \\\n",
       "0     34001005101         2              876            393            472   \n",
       "1     34001005102         2              852            450            388   \n",
       "2     34001005103         2             1206            517            672   \n",
       "3     34001005201         2              828            348            469   \n",
       "4     34001005202         2              868            579            282   \n",
       "...           ...       ...              ...            ...            ...   \n",
       "6356  34041115002         7              606            182            418   \n",
       "6357  34041115003         7              617            187            418   \n",
       "6358  34041115004         7              478            160            308   \n",
       "6359  34041115005         7              592            201            381   \n",
       "6360  34041115006         7              464            138            319   \n",
       "\n",
       "      Total_2020_Total  White_2020_Total  Hispanic_2020_Total  \\\n",
       "0                 1240               946                  128   \n",
       "1                 1913              1331                  211   \n",
       "2                 1760              1375                  177   \n",
       "3                 1311               906                  168   \n",
       "4                 1892               537                  336   \n",
       "...                ...               ...                  ...   \n",
       "6356               737               714                   11   \n",
       "6357               934               820                   60   \n",
       "6358               697               602                   66   \n",
       "6359               930               831                   47   \n",
       "6360               777               699                   30   \n",
       "\n",
       "      Black_2020_Total  Asian_2020_Total  Native_2020_Total  \\\n",
       "0                  102                66                 24   \n",
       "1                  286                84                 38   \n",
       "2                   78               106                 20   \n",
       "3                  150                64                 50   \n",
       "4                  598               450                 25   \n",
       "...                ...               ...                ...   \n",
       "6356                 3                 8                  0   \n",
       "6357                26                10                 14   \n",
       "6358                16                 4                  5   \n",
       "6359                27                11                 12   \n",
       "6360                27                 9                 10   \n",
       "\n",
       "      Pacific_2020_Total  \n",
       "0                      0  \n",
       "1                      4  \n",
       "2                      2  \n",
       "3                      5  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "6356                   0  \n",
       "6357                   0  \n",
       "6358                   0  \n",
       "6359                   0  \n",
       "6360                   0  \n",
       "\n",
       "[6361 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nh_precinct_data = pd.read_csv('precinct-data-congress-nj.csv')\n",
    "keepcolumns = ['GEOID20','District','Total_2020_Pres','Dem_2020_Pres','Rep_2020_Pres','Total_2020_Total','White_2020_Total','Hispanic_2020_Total','Black_2020_Total','Asian_2020_Total','Native_2020_Total','Pacific_2020_Total']\n",
    "nh_precinct_data = nh_precinct_data[keepcolumns]\n",
    "nh_precinct_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e75d5-6d29-4ab2-ab58-39c67f8b79f1",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data (uses shapely)\n",
    "\n",
    "This is data that represents the geography of the districts. It is needed to test for contiguity, or for any districting partitioning method based on geography. The data is in Shapely format. Each district is represented as a set of points that are connected to create the district shape (in the long/lat coordinates). Shapely geometric functions can be used to compare the shapes. These can be quite inefficient to run, so I am also providing you a pre-computed index that, for each district, lists the districts that are contiguous to it. You can see the code to generate the index in Contiguity.ipynb.\n",
    "\n",
    "To manipulate the shapes, cast them into Shapely Polygons (see example below) and you can use the Polygon properties and functions: https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html#shapely.Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3dbde7-e314-4fe0-9861-969d96e13645",
   "metadata": {},
   "outputs": [
    {
     "ename": "ShapefileException",
     "evalue": "Shapefile Reader requires a shapefile or file-like object.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mShapefileException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m shpfile \u001b[38;5;241m=\u001b[39m shp\u001b[38;5;241m.\u001b[39mReader(shp\u001b[38;5;241m=\u001b[39mshpfile, shx\u001b[38;5;241m=\u001b[39mshxfile, dbf\u001b[38;5;241m=\u001b[39mdbffile)\n\u001b[0;32m      7\u001b[0m nh_precinct_boundaries\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshpfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterShapeRecords\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeom\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# get geo bit\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# get db fields\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shapefile.py:3205\u001b[0m, in \u001b[0;36mReader.iterShapeRecords\u001b[1;34m(self, fields, bbox)\u001b[0m\n\u001b[0;32m   3196\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a generator of combination geometry/attribute records for\u001b[39;00m\n\u001b[0;32m   3197\u001b[0m \u001b[38;5;124;03mall records in a shapefile.\u001b[39;00m\n\u001b[0;32m   3198\u001b[0m \u001b[38;5;124;03mTo only read some of the fields, specify the 'fields' arg as a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3201\u001b[0m \u001b[38;5;124;03marg as a list or tuple of xmin,ymin,xmax,ymax.\u001b[39;00m\n\u001b[0;32m   3202\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3204\u001b[0m     \u001b[38;5;66;03m# iterate through all shapes and records\u001b[39;00m\n\u001b[1;32m-> 3205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3206\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterShapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterRecords\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   3208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mShapeRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3210\u001b[0m     \u001b[38;5;66;03m# only iterate where shape.bbox overlaps with the given bbox\u001b[39;00m\n\u001b[0;32m   3211\u001b[0m     \u001b[38;5;66;03m# TODO: internal __record method should be faster but would have to\u001b[39;00m\n\u001b[0;32m   3212\u001b[0m     \u001b[38;5;66;03m# make sure to seek to correct file location...\u001b[39;00m\n\u001b[0;32m   3213\u001b[0m \n\u001b[0;32m   3214\u001b[0m     \u001b[38;5;66;03m# fieldTuples,recLookup,recStruct = self.__recordFields(fields)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shapefile.py:2826\u001b[0m, in \u001b[0;36mReader.iterShapes\u001b[1;34m(self, bbox)\u001b[0m\n\u001b[0;32m   2820\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21miterShapes\u001b[39m(\u001b[38;5;28mself\u001b[39m, bbox: BBox \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Shape \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m   2821\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a generator of shapes in a shapefile. Useful\u001b[39;00m\n\u001b[0;32m   2822\u001b[0m \u001b[38;5;124;03m    for handling large shapefiles.\u001b[39;00m\n\u001b[0;32m   2823\u001b[0m \u001b[38;5;124;03m    To only read shapes within a given spatial region, specify the 'bbox'\u001b[39;00m\n\u001b[0;32m   2824\u001b[0m \u001b[38;5;124;03m    arg as a list or tuple of xmin,ymin,xmax,ymax.\u001b[39;00m\n\u001b[0;32m   2825\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2826\u001b[0m     shp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getFileObj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2827\u001b[0m     \u001b[38;5;66;03m# Found shapefiles which report incorrect\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m     \u001b[38;5;66;03m# shp file length in the header. Can't trust\u001b[39;00m\n\u001b[0;32m   2829\u001b[0m     \u001b[38;5;66;03m# that so we seek to the end of the file\u001b[39;00m\n\u001b[0;32m   2830\u001b[0m     \u001b[38;5;66;03m# and figure it out.\u001b[39;00m\n\u001b[0;32m   2831\u001b[0m     shp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\shapefile.py:2640\u001b[0m, in \u001b[0;36mReader.__getFileObj\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m   2637\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Checks to see if the requested shapefile file object is\u001b[39;00m\n\u001b[0;32m   2638\u001b[0m \u001b[38;5;124;03mavailable. If not a ShapefileException is raised.\"\"\"\u001b[39;00m\n\u001b[0;32m   2639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f:\n\u001b[1;32m-> 2640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ShapefileException(\n\u001b[0;32m   2641\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapefile Reader requires a shapefile or file-like object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2642\u001b[0m     )\n\u001b[0;32m   2643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshp \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshpLength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2644\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n",
      "\u001b[1;31mShapefileException\u001b[0m: Shapefile Reader requires a shapefile or file-like object."
     ]
    }
   ],
   "source": [
    "shpfile = 'Map_Data/nh_vtd_2020_bound/nh_vtd_2020_bound.shp'\n",
    "dbffile = 'Map_Data/nh_vtd_2020_bound/nh_vtd_2020_bound.dbf'\n",
    "shxfile = 'Map_Data/nh_vtd_2020_bound/nh_vtd_2020_bound.shx'\n",
    "\n",
    "\n",
    "shpfile = shp.Reader(shp=shpfile, shx=shxfile, dbf=dbffile)\n",
    "nh_precinct_boundaries={}\n",
    "for sr in shpfile.iterShapeRecords():\n",
    "    geom = sr.shape # get geo bit\n",
    "    rec = sr.record # get db fields\n",
    "    nh_precinct_boundaries[rec[3]]=geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba2224-64aa-485f-a3c5-1fef0feb2f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shxfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac244b-1f70-461f-b40e-9123f092fb03",
   "metadata": {},
   "source": [
    "### Example: Town of Barrington precinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fc071-31a3-4ec0-8da0-540a3ee3f504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#See for instance the precinct boundaries for the town of Barrington precinct\n",
    "print(Polygon(shape(nh_precinct_boundaries['33003SAND01'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453193c1-b51a-4f24-b7a1-5ecbfd9c9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see the coordinates of the bouding box of the district\n",
    "print(Polygon(shape(nh_precinct_boundaries['33017BARR01'])).bounds)\n",
    "# Or we can calculate the geographical centroid of the district\n",
    "print(Polygon(shape(nh_precinct_boundaries['33017BARR01'])).centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b419e97d-3996-40e8-a93f-2722fcc710ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also get the data from that district from our data table\n",
    "nh_precinct_data[nh_precinct_data['GEOID20']=='33017BARR01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf870e0-f364-4ce2-9c04-0e699f7052bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the current assignment of the district\n",
    "nh_current_assignment[nh_current_assignment['GEOID20']=='33017BARR01']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9050c5e-5d6a-4380-8692-326cc80e3dab",
   "metadata": {},
   "source": [
    "# How to get a district by name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd58b7-2393-4db5-96ef-a2015c8149ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#The name information is in the dbf file. You need the dbfread library to convert it to a dataframe\n",
    "from dbfread import DBF\n",
    "\n",
    "dbf = DBF(dbffile)\n",
    "nh_names_df = pd.DataFrame(iter(DBF(dbffile)))\n",
    "nh_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b7e90-957f-40ba-abe8-f718d6fa5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh_names_df[nh_names_df['NAME20'].str.contains('WILTON')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e696388-313f-4090-9035-09a7da258a19",
   "metadata": {},
   "source": [
    "# Some possible redistricting strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ba925-cd36-43d6-b2b8-76b9140c8292",
   "metadata": {},
   "source": [
    "### 1. Geographical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ced817-48c2-4b56-8a46-c274e5b9ff7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's start by creating simple geopgraphical maps, splitting the district in half North/South, or East/West.\n",
    "New Hampshire's bounding box is (-72.557247,42.69699,-70.610621,45.305476) (https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/)\n",
    "So let's start by splitting the state though the middle: everything west of longitude -71.583934 is in District 1, everything east is in District 2. We will use the precinct centroids to assign them.\n",
    "Import the Map to DRA to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30c782-b466-47d7-bb37-78b3cad6bd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nh_longitude_assignment = nh_current_assignment.copy()\n",
    "nh_longitude_assignment['District'] = 0\n",
    "for index, row in nh_longitude_assignment.iterrows():\n",
    "    try:\n",
    "        if shape(nh_precinct_boundaries[row['GEOID20']]).type == 'Polygon':\n",
    "            centroid = Polygon(shape(nh_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        elif shape(nh_precinct_boundaries[row['GEOID20']]).type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(nh_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        else:\n",
    "            print(shape(nh_precinct_boundaries[row['GEOID20']]).type)\n",
    "            pass\n",
    "        if centroid.x <= -71.583934:\n",
    "            nh_longitude_assignment.iloc[index,nh_longitude_assignment.columns.get_loc('District')] = 1\n",
    "        else:\n",
    "            nh_longitude_assignment.iloc[index,nh_longitude_assignment.columns.get_loc('District')] = 2\n",
    "    except KeyError: \n",
    "        pass\n",
    "#print(nh_longitude_assignment)\n",
    "nh_longitude_assignment.to_csv('Recitation maps/nh_centerlongitude_map.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4f3c0e-8ff3-4c75-a3d3-35ab5631d45b",
   "metadata": {},
   "source": [
    "Let's now split the state though the middle horizontally: everything north of latitude 44.001233 is in District 1, everything south is in District 2. We will use the precinct centroids to assign them. \n",
    "Import the Map to DRA to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddace2-10d0-4e2f-bd9d-8e99fee4657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh_latitude_assignment = nh_current_assignment.copy()\n",
    "nh_latitude_assignment['District'] = 0\n",
    "for index, row in nh_latitude_assignment.iterrows():\n",
    "    try:\n",
    "        if shape(nh_precinct_boundaries[row['GEOID20']]).type == 'Polygon':\n",
    "            centroid = Polygon(shape(nh_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        elif shape(nh_precinct_boundaries[row['GEOID20']]).type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(nh_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        else:\n",
    "            print(shape(nh_precinct_boundaries[row['GEOID20']]).type)\n",
    "            pass\n",
    "        if centroid.y <= 44.001233:\n",
    "            nh_latitude_assignment.iloc[index,nh_latitude_assignment.columns.get_loc('District')] = 1\n",
    "        else:\n",
    "            nh_latitude_assignment.iloc[index,nh_latitude_assignment.columns.get_loc('District')] = 2\n",
    "    except KeyError: \n",
    "        pass\n",
    "#print(nh_longitude_assignment)\n",
    "nh_latitude_assignment.to_csv('Recitation maps/nh_centerlatitude_map.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c92a31-4b48-40fd-8027-a4c9e1887923",
   "metadata": {},
   "source": [
    "### Look at the statistics for the maps\n",
    "Are they good maps?\n",
    "The population are completely different. We can redraw the maps using different split longitude (resp. latitude) values. You can code a binary search that stops when the two populations are within 5% for example.\n",
    "\n",
    "(There are four district for which the shapely data is not included, unfortunately this is from the census data so we will have to fix it manually later. Two of these have no population so are easy to ignore and just assign to the neighboring district. Two:  33013CONC05 and 33017SOME03 are populated district. You can hardcode their assignment for now.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956fb803-8360-4e6e-a87b-34d1d44c9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the population of a District:\n",
    "D1_list = nh_latitude_assignment[nh_latitude_assignment['District']==1]['GEOID20']\n",
    "D2_list = nh_latitude_assignment[nh_latitude_assignment['District']==2]['GEOID20']\n",
    "popD1= nh_precinct_data[nh_precinct_data['GEOID20'].isin(D1_list)]['Total_2020_Total'].sum()\n",
    "popD2= nh_precinct_data[nh_precinct_data['GEOID20'].isin(D2_list)]['Total_2020_Total'].sum()\n",
    "print('D1 pop = '+str(popD1)+', D2 pop = '+str(popD2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554f0a0-a61f-4bf3-92f9-88143f51aa70",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's write a function that gives us the population of the districts (returns a dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451608c7-8272-4ad0-8460-992c6161ce4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictPopulations(assignment,data_file, num_district):\n",
    "    population = {}\n",
    "    for i in range (1,num_district+1):\n",
    "        population[i] = data_file[data_file['GEOID20'].isin(assignment[assignment['District']==i]['GEOID20'])]['Total_2020_Total'].sum()\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b859dca-f174-40e6-af59-8466ecf2ab37",
   "metadata": {},
   "source": [
    "Let's see the split at Latitude = 43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff692b3-699a-4706-a1d8-eea75156b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh_latitude43_assignment = nh_current_assignment.copy()\n",
    "nh_latitude43_assignment['District'] = 0\n",
    "for index, row in nh_latitude43_assignment.iterrows():\n",
    "    try:\n",
    "        if shape(nh_precinct_boundaries[row['GEOID20']]).type == 'Polygon':\n",
    "            centroid = Polygon(shape(nh_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        elif shape(nh_precinct_boundaries[row['GEOID20']]).type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(nh_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        else:\n",
    "            print(shape(nh_precinct_boundaries[row['GEOID20']]).type)\n",
    "            pass\n",
    "        if centroid.y <= 43:\n",
    "            nh_latitude43_assignment.iloc[index,nh_latitude43_assignment.columns.get_loc('District')] = 1\n",
    "        else:\n",
    "            nh_latitude43_assignment.iloc[index,nh_latitude_assignment.columns.get_loc('District')] = 2\n",
    "    except KeyError: \n",
    "        pass\n",
    "nh_latitude43_assignment.to_csv('Recitation maps/nh_latitude43_map.csv',index=False)\n",
    "getDistrictPopulations(nh_latitude43_assignment,nh_precinct_data,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40742510-75f1-4d29-acc9-ddb080db31d0",
   "metadata": {},
   "source": [
    "Import the map to DRA. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7545e8a-b73c-4263-bac2-b5f09d7603ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Graph-based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f769ce22-4a65-4f41-971a-c1be277cc913",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can see the map as a graph, each precinct is a vertex, with edges drawn between neighboring precincts. We will use the NetworkX graph library. This will allow us to check for connectivity (contiguity) of the districts.\n",
    "\n",
    "First, we create a district graph. For this, we use the contiguity index I have pre-computed using Contiguity.ipynb, that is stored in Contiguity_nh.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c7ed1-b569-4876-aa65-a2b707f150cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh_contiguity = pd.read_csv('Contiguity_nh.csv', header=None)\n",
    "nh_contiguity.columns = ['Precinct','Neighbors']\n",
    "admin_water_precincts =['33017SOME03','33015ZZZZZZ']\n",
    "#Two precinct are administrative, have no population, and while they should be included in the assignment, they cannot be used for contiguity\n",
    "\n",
    "# Let's graph the district from the nh_latitude43_assignment map\n",
    "district1_graph = nx.Graph() #creates an empty undirected graph\n",
    "district1_nodes = nh_latitude43_assignment[nh_latitude43_assignment['District']==1]['GEOID20']\n",
    "district1_graph.add_nodes_from(district1_nodes)\n",
    "for id in district1_nodes:\n",
    "    neighbors = ast.literal_eval(nh_contiguity[nh_contiguity['Precinct']==id]['Neighbors'].values.tolist()[0])\n",
    "    # needed to convert string to list because the csv encodes the list as a string\n",
    "    for neighbor in neighbors:\n",
    "        district1_graph.add_edge(id,neighbor)\n",
    "\n",
    "print(nx.is_connected(district1_graph))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd178842-367b-4b03-a50e-7382ee38e0ce",
   "metadata": {},
   "source": [
    "Now let's add a disconnected precinct to the district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e571009-b5ec-49b4-9c07-dd0bddfe4192",
   "metadata": {},
   "outputs": [],
   "source": [
    "district1_graph.add_node(\"33007JEFF01\")\n",
    "neighbors = nh_contiguity[nh_contiguity['Precinct']==\"33007JEFF01\"]['Neighbors'].values.tolist()[0].replace('[','').replace(']','').replace(' ','').split(',')\n",
    "for neighbor in neighbors:\n",
    "        district1_graph.add_edge(id,neighbor)\n",
    "print(nx.is_connected(district1_graph))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ddbf15-a9a6-4947-a26d-090b95fccf93",
   "metadata": {},
   "source": [
    "So we can use the nx.is_connected function to check for contiguity. Here is a general function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fd6156-7605-472b-b3c6-f0c5f4979fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDistrictContiguous(district_num, assignment, contiguity_list, ignore_list=[]):\n",
    "    ## input:\n",
    "    ## district_num: the district number\n",
    "    ## assignment: the assignment from precinct to district\n",
    "    ## contiguity_list: the list of neighbors for each precinct, from the csv file\n",
    "    contiguity_list.columns = ['Precinct','Neighbors']\n",
    "    district_graph = nx.Graph() #creates an empty undirected graph\n",
    "    district_nodes = assignment[assignment['District']==district_num]['GEOID20'].tolist()\n",
    "    for i in ignore_list:\n",
    "        try:\n",
    "            district_nodes.remove(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    district_graph.add_nodes_from(district_nodes)\n",
    "    for id in district_nodes:\n",
    "        neighbors = ast.literal_eval(contiguity_list[contiguity_list['Precinct']==id]['Neighbors'].values.tolist()[0])\n",
    "        # needed to convert string to list because the csv encodes the list as a string\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in district_nodes:\n",
    "                district_graph.add_edge(id,neighbor)\n",
    "    return nx.is_connected(district_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9106a-81ec-44a6-895a-3a574f723ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "isDistrictContiguous(2,nh_latitude43_assignment,nh_contiguity,admin_water_precincts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86799775-e0de-40fb-8d99-31545e8307a9",
   "metadata": {},
   "source": [
    "#### Flood Fill Algorithm\n",
    "Here we will use a simple flood fill algorithm which will assign half of the precinct to D2 based on a BFS traversal.\n",
    "It does not consider population, but does check that both districts stay contiguous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c90b98-0aa6-4ae5-84d0-8eabd5463c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh_floodfill_assignment = nh_current_assignment.copy()\n",
    "nh_floodfill_assignment['District'] = 2 # Let's assign everything to D2, and build D1 via flood-fill.\n",
    "\n",
    "d1_size = 0\n",
    "\n",
    "next_precincts = [\"33005HINS01\"] #this is the district on the bottom left of the map. You can start anywhere else.\n",
    "visited = []\n",
    "\n",
    "while d1_size<163: #(there are 326 precincts total. We want to assign half to D1)\n",
    "    nh_floodfill_assignment.loc[nh_floodfill_assignment['GEOID20']==next_precincts[0],'District']=1\n",
    "    neighbors = ast.literal_eval(nh_contiguity[nh_contiguity['Precinct']==next_precincts[0]]['Neighbors'].values.tolist()[0])\n",
    "    for neighbor in neighbors:\n",
    "        #print(nh_floodfill_assignment[nh_floodfill_assignment['GEOID20']==neighbor]['District'].values[0])\n",
    "        #if nh_floodfill_assignment[nh_floodfill_assignment['GEOID20']==neighbor]['District'].values[0]!=1: #only add precinct we haven't visited\n",
    "        if neighbor not in visited and neighbor not in next_precincts : #only add if not visited and not already in list\n",
    "            next_precincts.append(neighbor)\n",
    "    d1_size += 1\n",
    "    visited.append(next_precincts[0])\n",
    "    next_precincts.pop(0)\n",
    "    \n",
    "    \n",
    "\n",
    "print(isDistrictContiguous(1,nh_floodfill_assignment,nh_contiguity))\n",
    "print(isDistrictContiguous(2,nh_floodfill_assignment,nh_contiguity))\n",
    "# Note: in some cases flood fill breaks contiguity, it may be a good idea to check for contiguity during flood fill.\n",
    "\n",
    "nh_floodfill_assignment.to_csv('Recitation maps/nh_floodfill_map.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cecf288-4593-4072-b584-7ace5735b598",
   "metadata": {},
   "source": [
    "Import the map in DRA. It is based on balancing the number of precints, so the population counts are off. You can adapt the code to take population count into account. You can also start from another district.\n",
    "\n",
    "Note that the algorithm can break contiguity (by splitting another district), so this should be checked during the traversal. In addition, it has to be applied carefully when you have more than 2 districts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731fc9f-70de-4a63-aed2-c40a70ff439d",
   "metadata": {},
   "source": [
    "### 3. From an Existing map - Flip Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3156410-de0b-470a-8953-d1921e743d5f",
   "metadata": {},
   "source": [
    "Let's try a random-based strategy which takes a precinct on the border of the two districts and flip it to the other district.\n",
    "Let's do this 10 times starting from the current official assignment map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd10f0-5938-406c-813d-96cfb1c27af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh_flipstep_assignment = nh_current_assignment.copy()\n",
    "\n",
    "## Let's do a simplistic approach. \n",
    "## First we randomly select 5 D1 precincts that border D2 and assign them to D2\n",
    "\n",
    "D1_border_precincts = []\n",
    "\n",
    "D1_list = nh_latitude_assignment[nh_latitude_assignment['District']==1]['GEOID20']\n",
    "for precinct in D1_list:\n",
    "    neighbors = ast.literal_eval(nh_contiguity[nh_contiguity['Precinct']==precinct]['Neighbors'].values.tolist()[0])\n",
    "    for neighbor in neighbors:\n",
    "        if nh_flipstep_assignment.loc[nh_flipstep_assignment['GEOID20']==neighbor,'District'].values.tolist()[0]==2:\n",
    "            #if one of the neighbor is in D2, then this is a border district\n",
    "            D1_border_precincts.append(precinct)\n",
    "            break\n",
    "#Sample 5 and flip them UNLESS it breaks contiguity\n",
    "flipped_precincts = np.random.choice(D1_border_precincts,5)\n",
    "for flip in flipped_precincts:\n",
    "    nh_flipstep_assignment.loc[nh_flipstep_assignment['GEOID20']==flip,'District']=2\n",
    "    #check if we broke contiguity and revert the flip if we did\n",
    "    if(isDistrictContiguous(1,nh_flipstep_assignment,nh_contiguity) is False or isDistrictContiguous(2,nh_flipstep_assignment,nh_contiguity) is False):\n",
    "        nh_flipstep_assignment.loc[nh_flipstep_assignment['GEOID20']==flip,'District']=1\n",
    "        print(\"Contiguity broken \" + flip)\n",
    "                                                                        \n",
    "\n",
    "## First we randomly select 5 DIFFERENT D2 precincts that border D1 and assign them to D1\n",
    "\n",
    "D2_border_precincts = []\n",
    "D2_list = nh_latitude_assignment[nh_latitude_assignment['District']==2]['GEOID20']\n",
    "for precinct in D2_list:\n",
    "    neighbors = ast.literal_eval(nh_contiguity[nh_contiguity['Precinct']==precinct]['Neighbors'].values.tolist()[0])\n",
    "    for neighbor in neighbors:\n",
    "        if nh_flipstep_assignment.loc[nh_flipstep_assignment['GEOID20']==neighbor,'District'].values.tolist()[0]==1 and precinct not in flipped_precincts:\n",
    "            #if one of the neighbor is in D2, then this is a border district. We do not want to re-flip a district we just flipped\n",
    "            D2_border_precincts.append(precinct)\n",
    "            break\n",
    "#Sample 5 and flip them UNLESS it breaks contiguity\n",
    "flipped_precincts = np.random.choice(D2_border_precincts,5)\n",
    "for flip in flipped_precincts:\n",
    "    nh_flipstep_assignment.loc[nh_flipstep_assignment['GEOID20']==flip,'District']=1\n",
    "    #check if we broke contiguity and revert the flip if we did\n",
    "    if(isDistrictContiguous(1,nh_flipstep_assignment,nh_contiguity) is False or isDistrictContiguous(2,nh_flipstep_assignment,nh_contiguity) is False):\n",
    "        nh_flipstep_assignment.loc[nh_flipstep_assignment['GEOID20']==flip,'District']=2\n",
    "        print(\"Contiguity broken \" + flip)\n",
    "                                                        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print(isDistrictContiguous(1,nh_flipstep_assignment,nh_contiguity))\n",
    "print(isDistrictContiguous(2,nh_flipstep_assignment,nh_contiguity))\n",
    "\n",
    "nh_flipstep_assignment.to_csv('Recitation maps/nh_flipstep_assignment.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaf6446-5043-4c30-abf5-7381829f7bfc",
   "metadata": {},
   "source": [
    "# Compactness\n",
    "You will also need some function to measure compactness. Here are some examples. You can write your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513250e-086e-4ece-bf7c-e01ce7a70afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_compactness(geom): # Polsby-Popper\n",
    "    p = geom.length\n",
    "    a = geom.area    \n",
    "    return (4*np.pi*a)/(p*p)\n",
    "\n",
    "def box_reock_compactness(geom): # Reock on a rectangle bounding box\n",
    "    a = geom.area \n",
    "    bb = geom.bounds # bounds gives you the minimum bounding box (rectangle)\n",
    "    bba = abs(bb[0]-bb[2])*abs(bb[1]-bb[3])\n",
    "    return a/bba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a1ff00-a8bd-4b10-992a-25eb2def75b1",
   "metadata": {},
   "source": [
    "We can compute the compactness of individual precincts. Here Barrington."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb897e10-e04e-4d15-9375-5687bf29362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_compactness(Polygon(shape(nh_precinct_boundaries['33003SAND01'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d786e6-2dc2-4b7b-a77f-8987c3a3f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_reock_compactness(Polygon(shape(nh_precinct_boundaries['33003SAND01'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f32691-6d9b-464d-9f4c-dc5dcc696d4f",
   "metadata": {},
   "source": [
    "To calculate the compactness of a District we need to create a shape (Multipolygon) that encloses all precincts in the District."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef08fc4-3165-4b82-b6fa-53b6ead4837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictShape(district_id, assignment, boundaries):\n",
    "    list_precincts = assignment[assignment['District']==district_id]['GEOID20']\n",
    "    precinct_shapes = []\n",
    "    for i in list_precincts:\n",
    "        if shape(boundaries[i]).type == 'Polygon':\n",
    "            precinct_shapes.append(Polygon(shape(boundaries[i])))\n",
    "        elif shape(boundaries[i]).type == 'MultiPolygon':\n",
    "            precinct_shapes.append(MultiPolygon(shape(boundaries[i])))      \n",
    "    district_shape = shapely.ops.unary_union(precinct_shapes)\n",
    "    #print(district_shape)\n",
    "    return district_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd71738-063f-46d3-8487-66fcce258bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of the current assignment\n",
    "print(\"D1 PP : \"+str(pp_compactness(getDistrictShape(1,nh_current_assignment,nh_precinct_boundaries))))\n",
    "print(\"D2 PP : \"+str(pp_compactness(getDistrictShape(2,nh_current_assignment,nh_precinct_boundaries))))\n",
    "print(\"D1 BR : \"+str(box_reock_compactness(getDistrictShape(1,nh_current_assignment,nh_precinct_boundaries))))\n",
    "print(\"D2 BR : \"+str(box_reock_compactness(getDistrictShape(2,nh_current_assignment,nh_precinct_boundaries))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c8f777-fc93-46c2-9eac-c1bee80aa35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of the floodfill assignment\n",
    "print(\"D1 PP : \"+str(pp_compactness(getDistrictShape(1,nh_floodfill_assignment,nh_precinct_boundaries))))\n",
    "print(\"D2 PP : \"+str(pp_compactness(getDistrictShape(2,nh_floodfill_assignment,nh_precinct_boundaries))))\n",
    "print(\"D1 BR : \"+str(box_reock_compactness(getDistrictShape(1,nh_floodfill_assignment,nh_precinct_boundaries))))\n",
    "print(\"D2 BR : \"+str(box_reock_compactness(getDistrictShape(2,nh_floodfill_assignment,nh_precinct_boundaries))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a95c4-14cb-4b68-8354-f8ae9470c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of the 43 Latitude assignment\n",
    "print(\"D1 PP : \"+str(pp_compactness(getDistrictShape(1,nh_latitude43_assignment,nh_precinct_boundaries))))\n",
    "print(\"D2 PP : \"+str(pp_compactness(getDistrictShape(2,nh_latitude43_assignment,nh_precinct_boundaries))))\n",
    "print(\"D1 BR : \"+str(box_reock_compactness(getDistrictShape(1,nh_latitude43_assignment,nh_precinct_boundaries))))\n",
    "print(\"D2 BR : \"+str(box_reock_compactness(getDistrictShape(2,nh_latitude43_assignment,nh_precinct_boundaries))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e762428-627e-431b-9178-e25c0c50f340",
   "metadata": {},
   "source": [
    "### This should give you the information you need to start creating your own maps.\n",
    "NJ_Redistricing_StartingPoint.ipnyb has an example map for NJ. \n",
    "I suggest you test your algorithms on NH first as running times will be slower on a small map. You can of course change the number of districts in your test code you test different approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8deec74-ffb2-439f-8c40-20ec7f42ac3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
