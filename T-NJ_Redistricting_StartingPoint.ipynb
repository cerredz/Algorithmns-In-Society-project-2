{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0c8991",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d053be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9044994",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a92056",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c0d7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a3d493-83fb-4965-bdcb-f1054425e86e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: geojson in /usr/local/venv/lib/python3.12/site-packages (3.2.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: shapely in /usr/local/venv/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/venv/lib/python3.12/site-packages (from shapely) (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyShp in /usr/local/venv/lib/python3.12/site-packages (2.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in /usr/local/venv/lib/python3.12/site-packages (3.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install geojson\n",
    "!pip install shapely\n",
    "!pip install PyShp\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a7f250-1f24-4f02-832b-1df2dceaa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Polygon,shape,MultiPolygon\n",
    "import shapely.ops\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1549e7-0856-443a-aedc-df06d9caf33a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad28b0c5-f5b6-4baf-9295-07dbff55df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDistrictContiguous(district_num, assignment, contiguity_list, print_isolates=False, ignore_list=[]):\n",
    "    ## input:\n",
    "    ## district_num: the district number\n",
    "    ## assignment: the assignment from precinct to district\n",
    "    ## contiguity_list: the list of neighbors for each precinct, from the csv file\n",
    "    contiguity_list.columns = ['Precinct','Neighbors']\n",
    "    district_graph = nx.Graph() #creates an empty undirected graph\n",
    "    district_nodes = assignment[assignment['District']==district_num]['GEOID20'].tolist()\n",
    "    for i in ignore_list:\n",
    "        try:\n",
    "            district_nodes.remove(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    district_graph.add_nodes_from(district_nodes)\n",
    "    for id in district_nodes:\n",
    "        neighbors = ast.literal_eval(contiguity_list[contiguity_list['Precinct']==id]['Neighbors'].values.tolist()[0])\n",
    "        # needed to convert string to list because the csv encodes the list as a string\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in district_nodes:\n",
    "                district_graph.add_edge(id,neighbor)\n",
    "    if(print_isolates):\n",
    "        print(list(nx.isolates(district_graph)))\n",
    "    return nx.is_connected(district_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474da28a-35a4-4115-b19e-9439d1044e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictPopulations(assignment,data_file, num_district):\n",
    "    population = {}\n",
    "    for i in range (1,num_district+1):\n",
    "        population[i] = data_file[data_file['GEOID20'].isin(assignment[assignment['District']==i]['GEOID20'])]['Total_2020_Total'].sum()\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c27697-04a7-4169-843b-ce2d98622efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictShape(district_id, assignment, boundaries):\n",
    "    list_precincts = assignment[assignment['District']==district_id]['GEOID20']\n",
    "    precinct_shapes = []\n",
    "    for i in list_precincts:\n",
    "        if shape(boundaries[i]).geom_type == 'Polygon':\n",
    "            precinct_shapes.append(Polygon(shape(boundaries[i])))\n",
    "        elif shape(boundaries[i]).geom_type == 'MultiPolygon':\n",
    "            precinct_shapes.append(MultiPolygon(shape(boundaries[i])))      \n",
    "    district_shape = shapely.ops.unary_union(precinct_shapes)\n",
    "    #print(district_shape)\n",
    "    return district_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e8260f-2f6a-497e-8ff6-51dd9a767180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_compactness(geom): # Polsby-Popper\n",
    "    p = geom.length\n",
    "    a = geom.area    \n",
    "    return (4*np.pi*a)/(p*p)\n",
    "\n",
    "def box_reock_compactness(geom): # Reock on a rectangle bounding box\n",
    "    a = geom.area \n",
    "    bb = geom.bounds # bounds gives you the minimum bounding box (rectangle)\n",
    "    bba = abs(bb[0]-bb[2])*abs(bb[1]-bb[3])\n",
    "    return a/bba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959227a9-93f8-47fa-87ef-02037facafb9",
   "metadata": {},
   "source": [
    "# This Notebook will help you get started on NJ\n",
    "The data is in Canvas, you should upload it to your Google Drive first (if using Colab), or local filesystem (if using Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69143d08-629d-436a-8687-7a5d3bcb5aa3",
   "metadata": {},
   "source": [
    "### This is the current assignment of precinct to congressional districts (12 of them for NJ)\n",
    "Note that the map shown in DRA is slightly different. This is because some precincts are split in the real assignment, and some additional precinct are created to handle special situations such as prisoners and overseas citizens. You can ignore this for the class project and just use the data and functions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0c2b03-9b2f-46c5-b619-0709ca555c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>District</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34033020001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34033001501</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34033042009</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34033000703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34033042001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>34039045302</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>34039045303</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>34039045404</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>34039045801</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>34039045802</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID20  District\n",
       "0     34033020001         2\n",
       "1     34033001501         2\n",
       "2     34033042009         2\n",
       "3     34033000703         2\n",
       "4     34033042001         2\n",
       "...           ...       ...\n",
       "6356  34039045302         7\n",
       "6357  34039045303         7\n",
       "6358  34039045404         7\n",
       "6359  34039045801         7\n",
       "6360  34039045802         7\n",
       "\n",
       "[6361 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj_current_assignment = pd.read_csv('Map_Data/precinct-assignments-congress-nj.csv')\n",
    "nj_current_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bce06-2f20-4f82-959e-a95f91e25ba5",
   "metadata": {},
   "source": [
    "### This is the current demographic and voter data\n",
    "The data has a lot of attributes that lists voters of different demographics and parties in different elections. You can look at the data Dictionary on Canvas to get details. For this recitation we will only keep votes from the 2020  presidential election and the total 2020 population counts. You can use additional columns (e.g., Governor's elections results, voting age (VAP) population counts, or the composite Dem/Rep score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d13a23f-3b65-4852-a42d-3a87867f3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>District</th>\n",
       "      <th>Total_2020_Pres</th>\n",
       "      <th>Dem_2020_Pres</th>\n",
       "      <th>Rep_2020_Pres</th>\n",
       "      <th>Total_2020_Total</th>\n",
       "      <th>White_2020_Total</th>\n",
       "      <th>Hispanic_2020_Total</th>\n",
       "      <th>Black_2020_Total</th>\n",
       "      <th>Asian_2020_Total</th>\n",
       "      <th>Native_2020_Total</th>\n",
       "      <th>Pacific_2020_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34001005101</td>\n",
       "      <td>2</td>\n",
       "      <td>876</td>\n",
       "      <td>393</td>\n",
       "      <td>472</td>\n",
       "      <td>1240</td>\n",
       "      <td>946</td>\n",
       "      <td>128</td>\n",
       "      <td>102</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34001005102</td>\n",
       "      <td>2</td>\n",
       "      <td>852</td>\n",
       "      <td>450</td>\n",
       "      <td>388</td>\n",
       "      <td>1913</td>\n",
       "      <td>1331</td>\n",
       "      <td>211</td>\n",
       "      <td>286</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34001005103</td>\n",
       "      <td>2</td>\n",
       "      <td>1206</td>\n",
       "      <td>517</td>\n",
       "      <td>672</td>\n",
       "      <td>1760</td>\n",
       "      <td>1375</td>\n",
       "      <td>177</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34001005201</td>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>348</td>\n",
       "      <td>469</td>\n",
       "      <td>1311</td>\n",
       "      <td>906</td>\n",
       "      <td>168</td>\n",
       "      <td>150</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34001005202</td>\n",
       "      <td>2</td>\n",
       "      <td>868</td>\n",
       "      <td>579</td>\n",
       "      <td>282</td>\n",
       "      <td>1892</td>\n",
       "      <td>537</td>\n",
       "      <td>336</td>\n",
       "      <td>598</td>\n",
       "      <td>450</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>34041115002</td>\n",
       "      <td>7</td>\n",
       "      <td>606</td>\n",
       "      <td>182</td>\n",
       "      <td>418</td>\n",
       "      <td>737</td>\n",
       "      <td>714</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>34041115003</td>\n",
       "      <td>7</td>\n",
       "      <td>617</td>\n",
       "      <td>187</td>\n",
       "      <td>418</td>\n",
       "      <td>934</td>\n",
       "      <td>820</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>34041115004</td>\n",
       "      <td>7</td>\n",
       "      <td>478</td>\n",
       "      <td>160</td>\n",
       "      <td>308</td>\n",
       "      <td>697</td>\n",
       "      <td>602</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>34041115005</td>\n",
       "      <td>7</td>\n",
       "      <td>592</td>\n",
       "      <td>201</td>\n",
       "      <td>381</td>\n",
       "      <td>930</td>\n",
       "      <td>831</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>34041115006</td>\n",
       "      <td>7</td>\n",
       "      <td>464</td>\n",
       "      <td>138</td>\n",
       "      <td>319</td>\n",
       "      <td>777</td>\n",
       "      <td>699</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID20  District  Total_2020_Pres  Dem_2020_Pres  Rep_2020_Pres  \\\n",
       "0     34001005101         2              876            393            472   \n",
       "1     34001005102         2              852            450            388   \n",
       "2     34001005103         2             1206            517            672   \n",
       "3     34001005201         2              828            348            469   \n",
       "4     34001005202         2              868            579            282   \n",
       "...           ...       ...              ...            ...            ...   \n",
       "6356  34041115002         7              606            182            418   \n",
       "6357  34041115003         7              617            187            418   \n",
       "6358  34041115004         7              478            160            308   \n",
       "6359  34041115005         7              592            201            381   \n",
       "6360  34041115006         7              464            138            319   \n",
       "\n",
       "      Total_2020_Total  White_2020_Total  Hispanic_2020_Total  \\\n",
       "0                 1240               946                  128   \n",
       "1                 1913              1331                  211   \n",
       "2                 1760              1375                  177   \n",
       "3                 1311               906                  168   \n",
       "4                 1892               537                  336   \n",
       "...                ...               ...                  ...   \n",
       "6356               737               714                   11   \n",
       "6357               934               820                   60   \n",
       "6358               697               602                   66   \n",
       "6359               930               831                   47   \n",
       "6360               777               699                   30   \n",
       "\n",
       "      Black_2020_Total  Asian_2020_Total  Native_2020_Total  \\\n",
       "0                  102                66                 24   \n",
       "1                  286                84                 38   \n",
       "2                   78               106                 20   \n",
       "3                  150                64                 50   \n",
       "4                  598               450                 25   \n",
       "...                ...               ...                ...   \n",
       "6356                 3                 8                  0   \n",
       "6357                26                10                 14   \n",
       "6358                16                 4                  5   \n",
       "6359                27                11                 12   \n",
       "6360                27                 9                 10   \n",
       "\n",
       "      Pacific_2020_Total  \n",
       "0                      0  \n",
       "1                      4  \n",
       "2                      2  \n",
       "3                      5  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "6356                   0  \n",
       "6357                   0  \n",
       "6358                   0  \n",
       "6359                   0  \n",
       "6360                   0  \n",
       "\n",
       "[6361 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj_precinct_data = pd.read_csv('Map_Data/precinct-data-congress-nj.csv')\n",
    "keepcolumns = ['GEOID20','District','Total_2020_Pres','Dem_2020_Pres','Rep_2020_Pres','Total_2020_Total','White_2020_Total','Hispanic_2020_Total','Black_2020_Total','Asian_2020_Total','Native_2020_Total','Pacific_2020_Total']\n",
    "nj_precinct_data = nj_precinct_data[keepcolumns]\n",
    "nj_precinct_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e75d5-6d29-4ab2-ab58-39c67f8b79f1",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data (uses shapely)\n",
    "\n",
    "This is data that represents the geography of the districts. It is needed to test for contiguity, or for any districting partitioning method based on geography. The data is in Shapely format. Each district is represented as a set of points that are connected to create the district shape (in the long/lat coordinates). Shapely geometric functions can be used to compare the shapes. These can be quite inefficient to run, so I am also providing you a pre-computed index that, for each district, lists the districts that are contiguous to it. You can see the code to generate the index in Contiguity.ipynb.\n",
    "\n",
    "To manipulate the shapes, cast them into Shapely Polygons (see example below) and you can use the Polygon properties and functions: https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html#shapely.Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3dbde7-e314-4fe0-9861-969d96e13645",
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shp'\n",
    "dbffile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.dbf'\n",
    "shxfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shx'\n",
    "\n",
    "\n",
    "shpfile = shp.Reader(shp=shpfile, shx=shxfile, dbf=dbffile)\n",
    "nj_precinct_boundaries={}\n",
    "for sr in shpfile.iterShapeRecords():\n",
    "    geom = sr.shape # get geo bit\n",
    "    rec = sr.record # get db fields\n",
    "    nj_precinct_boundaries[rec[3]]=geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a473b-0936-4c0e-93cc-850329eaa553",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data \n",
    "\n",
    "This use the contiguity index I have pre-computed using Contiguity.ipynb, that is stored in Contiguity_nj.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c9f089-caad-45b3-b795-71793bcfedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_contiguity = pd.read_csv('Contiguity_nj.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2c4cda-bb3c-4392-9df0-5e075c19c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District 1 True\n",
      "District 2 True\n",
      "District 3 True\n",
      "District 4 True\n",
      "District 5 True\n",
      "District 6 True\n",
      "District 7 True\n",
      "District 8 True\n",
      "District 9 True\n",
      "District 10 True\n",
      "District 11 True\n",
      "District 12 True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    print(\"District \"+str(i)+\" \"+str(isDistrictContiguous(i, nj_current_assignment, nj_contiguity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96bad083-6853-462f-be62-38ff2f84e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 PP : 0.41768102211569347\n",
      "D1 BR : 0.45075813446417157\n",
      "D2 PP : 0.2632665176502347\n",
      "D2 BR : 0.38278056561756263\n",
      "D3 PP : 0.2280937682959879\n",
      "D3 BR : 0.38134920642809134\n",
      "D4 PP : 0.24812480573284196\n",
      "D4 BR : 0.5390173747196018\n",
      "D5 PP : 0.2410116694999733\n",
      "D5 BR : 0.36320426268176653\n",
      "D6 PP : 0.14677124653853732\n",
      "D6 BR : 0.32853496486220907\n",
      "D7 PP : 0.20246375771704353\n",
      "D7 BR : 0.44049249082841035\n",
      "D8 PP : 0.11227347882175574\n",
      "D8 BR : 0.36670629634952656\n",
      "D9 PP : 0.1683197710884751\n",
      "D9 BR : 0.29705227593212374\n",
      "D10 PP : 0.12061263370064262\n",
      "D10 BR : 0.34528827672774703\n",
      "D11 PP : 0.22236600778446886\n",
      "D11 BR : 0.5557086439792166\n",
      "D12 PP : 0.1620092442171186\n",
      "D12 BR : 0.38520439164401626\n"
     ]
    }
   ],
   "source": [
    "#Compactness of the current assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f43f2ef1-b4be-4c73-b87a-f6e9f6e9b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 775340, 2: 778354, 3: 778489, 4: 767834, 5: 774454, 6: 778516, 7: 785173, 8: 800074, 9: 766863, 10: 746178, 11: 769523, 12: 768196}\n"
     ]
    }
   ],
   "source": [
    "# District Population of the current assignment\n",
    "print(getDistrictPopulations(nj_current_assignment,nj_precinct_data, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e696388-313f-4090-9035-09a7da258a19",
   "metadata": {},
   "source": [
    "# A simple geographical  redistricting strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ced817-48c2-4b56-8a46-c274e5b9ff7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can create a simple geopgraphical map, like we did for NH. In this case, we have 12 districts, so let's splitting the district in half North/South, and in 6th  East/West. \n",
    "New Hampshire's bounding box is (-75.559614,38.928519,-73.893979,41.357423) (https://anthonylouisdagostino.com/bounding-boxes-for-all-us-states/)\n",
    "So let's start by splitting the state approximately though the middle longitude (-74.72) : everything west of longitude -71.583934 is in odd Districts, everything east is in even Districts. We will use the precinct centroids to assign them. Then we will divide each half per latitude on the ranges  (38.92, 39.3, 39.7, 40.1, 40.5,40.9,41.35)\n",
    "Import the Map to DRA to look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da30c782-b466-47d7-bb37-78b3cad6bd34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'Recitation_maps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#print(nh_longitude_assignment)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[43mnj_longlat_assignment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRecitation_maps/nj_longlat_map.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/venv/lib/python3.12/site-packages/pandas/core/generic.py:3986\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3975\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3977\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3978\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3979\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3983\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3984\u001b[0m )\n\u001b[0;32m-> 3986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3989\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4003\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/usr/local/venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/usr/local/venv/lib/python3.12/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/venv/lib/python3.12/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'Recitation_maps'"
     ]
    }
   ],
   "source": [
    "nj_longlat_assignment = nj_current_assignment.copy()\n",
    "nj_longlat_assignment['District'] = 0\n",
    "for index, row in nj_longlat_assignment.iterrows():\n",
    "    try:\n",
    "        if shape(nj_precinct_boundaries[row['GEOID20']]).geom_type == 'Polygon':\n",
    "            centroid = Polygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        elif shape(nj_precinct_boundaries[row['GEOID20']]).geom_type == 'MultiPolygon':\n",
    "            centroid = MultiPolygon(shape(nj_precinct_boundaries[row['GEOID20']])).centroid\n",
    "        else:\n",
    "            print(shape(nj_precinct_boundaries[row['GEOID20']]).geom_type)\n",
    "            pass\n",
    "        if centroid.x <= -74.72:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 1\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 3\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 5\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 7\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 9\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 11\n",
    "        else:\n",
    "            if centroid.y <= 39.3:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 2\n",
    "            elif centroid.y <= 39.7:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 4\n",
    "            elif centroid.y <= 40.1:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 6\n",
    "            elif centroid.y <= 40.5:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 8\n",
    "            elif centroid.y <= 40.9:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 10\n",
    "            else:\n",
    "                nj_longlat_assignment.iloc[index,nj_longlat_assignment.columns.get_loc('District')] = 12\n",
    "    except KeyError: \n",
    "        pass\n",
    "#print(nh_longitude_assignment)\n",
    "nj_longlat_assignment.to_csv('Recitation_maps/nj_longlat_map.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00508f-3df2-487c-90ac-56a7af050c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compactness of this Longlat assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_longlat_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265c674a-6122-4440-a87a-9b5b4250f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# District Population of this longlat assignment\n",
    "print(getDistrictPopulations(nj_longlat_assignment,nj_precinct_data, 12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f943977-f3a0-41b8-930e-6e26d74092f2",
   "metadata": {},
   "source": [
    "# Now create your own redistricting maps\n",
    "Remember to check for contiguity, and to ensure that the population of the districts are balanced (which is not the case in the example above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65fda189-958e-4639-8c9e-78d618ea055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2326068/2269566849.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  adj_list[row[0]] = set(ast.literal_eval(row[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Population: 9288994\n",
      "Target Population per District: 774082.83\n",
      "Data prep complete. Fast dictionaries are built.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. PREP YOUR DATA FOR SPEED ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "# --- Convert existing DataFrames into fast Dictionaries ---\n",
    "# (Assumes 'nj_current_assignment', 'nj_contiguity', 'nj_precinct_data',\n",
    "#  and 'nj_precinct_boundaries' are loaded from the cells above)\n",
    "\n",
    "# Convert the assignment DataFrame to a dictionary: {GEOID: District}\n",
    "# This is your main \"map\" object\n",
    "current_map = pd.Series(\n",
    "    nj_current_assignment['District'].values, \n",
    "    index=nj_current_assignment['GEOID20']\n",
    ").to_dict()\n",
    "\n",
    "# Convert contiguity DataFrame to a dictionary: {GEOID: {Neighbor1, Neighbor2, ...}}\n",
    "adj_list = {}\n",
    "for index, row in nj_contiguity.iterrows():\n",
    "    # row[0] is the Precinct GEOID, row[1] is the string-list of neighbors\n",
    "    adj_list[row[0]] = set(ast.literal_eval(row[1]))\n",
    "\n",
    "# Convert precinct data DataFrame to a dictionary: {GEOID: {col: val, ...}}\n",
    "precinct_data = nj_precinct_data.set_index('GEOID20').to_dict('index')\n",
    "\n",
    "# Store the shapefile boundaries (already loaded)\n",
    "boundaries = nj_precinct_boundaries\n",
    "\n",
    "# --- Calculate Population Targets ---\n",
    "total_pop = nj_precinct_data['Total_2020_Total'].sum()\n",
    "target_pop = total_pop / 12\n",
    "print(f\"Total Population: {total_pop}\")\n",
    "print(f\"Target Population per District: {target_pop:.2f}\")\n",
    "\n",
    "# --- Keep copies of the original DataFrames for the GIVEN helper functions ---\n",
    "# We need these *once* to get the initial population\n",
    "nj_precinct_data_df = nj_precinct_data.copy()\n",
    "nj_contiguity_df = nj_contiguity.copy()\n",
    "\n",
    "print(\"Data prep complete. Fast dictionaries are built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d65247-a691-4305-a09c-2904846c5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast helper functions are defined.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. YOUR NEW, FAST HELPER FUNCTIONS ---\n",
    "\n",
    "# Finds all precincts on the border of two different districts\n",
    "def get_border_precincts(current_map_dict, adj_list_dict):\n",
    "    border_precincts = []\n",
    "    for precinct_id, district_id in current_map_dict.items():\n",
    "        my_district = district_id\n",
    "        # Use .get() for safety, in case a precinct has no neighbors\n",
    "        for neighbor_id in adj_list_dict.get(precinct_id, set()):\n",
    "            # Check if neighbor is in the map\n",
    "            if neighbor_id in current_map_dict:\n",
    "                # If a neighbor is in a DIFFERENT district, this is a border precinct\n",
    "                if current_map_dict[neighbor_id] != my_district:\n",
    "                    border_precincts.append(precinct_id)\n",
    "                    break # Stop checking neighbors, we know it's a border\n",
    "    return border_precincts\n",
    "\n",
    "# A blazing-fast population check that just reads a 12-item dictionary\n",
    "def check_balance_from_dict(district_pops, target_pop, tolerance=0.05):\n",
    "    # This tolerance (0.05 = 5%) is from the assignment\n",
    "    for pop in district_pops.values():\n",
    "        if not (target_pop * (1 - tolerance) < pop < target_pop * (1 + tolerance)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# A helper to get vote totals for one district\n",
    "def get_district_vote_totals(district_id, current_map_dict, precinct_data_dict):\n",
    "    dem_votes = 0\n",
    "    rep_votes = 0\n",
    "    for precinct_id, d_id in current_map_dict.items():\n",
    "        if d_id == district_id:\n",
    "            dem_votes += precinct_data_dict[precinct_id].get('Dem_2020_Pres', 0)\n",
    "            rep_votes += precinct_data_dict[precinct_id].get('Rep_2020_Pres', 0)\n",
    "    return dem_votes, rep_votes\n",
    "\n",
    "# Helper to get the total number of seats won\n",
    "def get_total_seats(current_map_dict, precinct_data_dict):\n",
    "    total_seats_won = 0\n",
    "    # Assumes districts are 1-12\n",
    "    for i in range(1, 13):\n",
    "        dem_votes, rep_votes = get_district_vote_totals(i, current_map_dict, precinct_data_dict)\n",
    "        if dem_votes > rep_votes:\n",
    "            total_seats_won += 1\n",
    "    return total_seats_won\n",
    "\n",
    "# A new, FAST contiguity check that uses our dictionaries\n",
    "def is_contiguous_fast(district_id, current_map_dict, adj_list_dict):\n",
    "    # Find all precincts in this district\n",
    "    nodes_in_district = [\n",
    "        precinct_id for precinct_id, d_id in current_map_dict.items() \n",
    "        if d_id == district_id\n",
    "    ]\n",
    "    if not nodes_in_district:\n",
    "        return True # An empty district is \"contiguous\"\n",
    "\n",
    "    # Build a graph *only* for these nodes\n",
    "    district_graph = nx.Graph()\n",
    "    district_graph.add_nodes_from(nodes_in_district)\n",
    "    \n",
    "    start_node = nodes_in_district[0] # Pick one node to start traversal\n",
    "    \n",
    "    for precinct_id in nodes_in_district:\n",
    "        # Look at neighbors (fast lookup)\n",
    "        for neighbor in adj_list_dict.get(precinct_id, set()):\n",
    "            # If the neighbor is ALSO in the district, add an edge\n",
    "            if neighbor in current_map_dict and current_map_dict[neighbor] == district_id:\n",
    "                district_graph.add_edge(precinct_id, neighbor)\n",
    "                \n",
    "    # Check if the graph is connected\n",
    "    return nx.is_connected(district_graph)\n",
    "\n",
    "print(\"Fast helper functions are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "859c920d-4d66-41af-9eff-64a21f2413ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting UNFAIR optimization. Initial Score: 10000.0001 (10 seats)\n",
      "Iteration 5000, Score: 10000.0000 (10 seats)\n",
      "Iteration 10000, Score: 10000.0000 (10 seats)\n",
      "Iteration 15000, Score: 10000.0000 (10 seats)\n",
      "Iteration 20000, Score: 10000.0000 (10 seats)\n",
      "Iteration 25000, Score: 10000.0000 (10 seats)\n",
      "Iteration 30000, Score: 10000.0000 (10 seats)\n",
      "Iteration 35000, Score: 10000.0000 (10 seats)\n",
      "Iteration 40000, Score: 10000.0000 (10 seats)\n",
      "Iteration 45000, Score: 10000.0000 (10 seats)\n",
      "Optimization Complete! Final Score: 10000.000038313661 (10 seats)\n",
      "Saved map to unfair_map.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 3. THE FINAL OPTIMIZED LOOP (UNFAIR MAP) ---\n",
    "\n",
    "# --- 1. SETUP: CALCULATE STATE *ONCE* ---\n",
    "map_to_optimize = current_map.copy()\n",
    "\n",
    "# Get initial population state (FAST, uses the GIVEN slow function *once*)\n",
    "df_map_for_pop = pd.DataFrame(map_to_optimize.items(), columns=['GEOID20', 'District'])\n",
    "district_populations = getDistrictPopulations(df_map_for_pop, nj_precinct_data_df, 12)\n",
    "\n",
    "# Get initial partisan state (FAST)\n",
    "current_seats_won = get_total_seats(map_to_optimize, precinct_data)\n",
    "\n",
    "# Calculate the initial hybrid score\n",
    "# We use 1 / std_dev so that a *lower* std_dev (better balance) gives a *higher* score\n",
    "current_pop_balance_score = 1.0 / np.std(list(district_populations.values()))\n",
    "# The score: Seats are *most* important (x1000), pop balance is the tie-breaker\n",
    "current_score = (current_seats_won * 1000) + current_pop_balance_score\n",
    "\n",
    "print(f\"Starting UNFAIR optimization. Initial Score: {current_score:.4f} ({current_seats_won} seats)\")\n",
    "\n",
    "# --- 2. MAIN LOOP ---\n",
    "# Set to 50,000 for a good run. Can be 100k+\n",
    "# For a quick test, use 1000.\n",
    "ITERATIONS = 50000 \n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    if i % 5000 == 0 and i > 0: # Print every 5000 iterations\n",
    "        print(f\"Iteration {i}, Score: {current_score} ({current_seats_won} seats)\")\n",
    "\n",
    "    # 1. Get a random precinct to flip\n",
    "    border_precincts = get_border_precincts(map_to_optimize, adj_list)\n",
    "    if not border_precincts: continue\n",
    "    precinct_to_flip = random.choice(border_precincts)\n",
    "    old_district = map_to_optimize[precinct_to_flip]\n",
    "    \n",
    "    # 2. Find a valid district to flip into\n",
    "    possible_new_districts = []\n",
    "    for neighbor in adj_list[precinct_to_flip]:\n",
    "        if neighbor in map_to_optimize and map_to_optimize[neighbor] != old_district:\n",
    "            possible_new_districts.append(map_to_optimize[neighbor])\n",
    "    if not possible_new_districts: continue\n",
    "    new_district = random.choice(possible_new_districts)\n",
    "\n",
    "    # --- 3. UPDATE STATE AND CHECK CONSTRAINTS (ALL FAST) ---\n",
    "    \n",
    "    # A. Update population state\n",
    "    pop_to_move = precinct_data[precinct_to_flip]['Total_2020_Total']\n",
    "    district_populations[old_district] -= pop_to_move\n",
    "    district_populations[new_district] += pop_to_move\n",
    "    \n",
    "    # B. Make the temporary map flip\n",
    "    map_to_optimize[precinct_to_flip] = new_district\n",
    "    \n",
    "    # C. Fast constraint check\n",
    "    constraints_met = (\n",
    "        check_balance_from_dict(district_populations, target_pop) and\n",
    "        is_contiguous_fast(old_district, map_to_optimize, adj_list) and\n",
    "        is_contiguous_fast(new_district, map_to_optimize, adj_list)\n",
    "    )\n",
    "\n",
    "    # --- 4. EVALUATE THE MOVE ---\n",
    "    if constraints_met:\n",
    "        # 4a. Calculate new score (ALL FAST)\n",
    "        new_seats_won = get_total_seats(map_to_optimize, precinct_data)\n",
    "        new_pop_balance_score = 1.0 / np.std(list(district_populations.values()))\n",
    "        new_score = (new_seats_won * 1000) + new_pop_balance_score\n",
    "\n",
    "        # 4b. Simulated Annealing Logic\n",
    "        move_kept = False\n",
    "        if new_score > current_score:\n",
    "            move_kept = True # Always keep a better move\n",
    "        else:\n",
    "            # Maybe keep a worse move\n",
    "            temperature = 1.0 / (i + 1) # \"Cooling\" schedule\n",
    "            acceptance_prob = math.exp((new_score - current_score) / temperature)\n",
    "            if random.random() < acceptance_prob:\n",
    "                move_kept = True\n",
    "\n",
    "        if move_kept:\n",
    "            # Keep the move: update our state\n",
    "            current_score = new_score\n",
    "            current_seats_won = new_seats_won\n",
    "        else:\n",
    "            # Reject the move: undo everything\n",
    "            map_to_optimize[precinct_to_flip] = old_district\n",
    "            district_populations[old_district] += pop_to_move\n",
    "            district_populations[new_district] -= pop_to_move\n",
    "            \n",
    "    else:\n",
    "        # FAILED constraints: undo everything\n",
    "        map_to_optimize[precinct_to_flip] = old_district\n",
    "        district_populations[old_district] += pop_to_move\n",
    "        district_populations[new_district] -= pop_to_move\n",
    "\n",
    "# --- 5. FINISH AND SAVE ---\n",
    "print(f\"Optimization Complete! Final Score: {current_score} ({current_seats_won} seats)\")\n",
    "\n",
    "final_map_df = pd.DataFrame(map_to_optimize.items(), columns=['GEOID20', 'District'])\n",
    "final_map_df.to_csv('unfair_map.csv', index=False)\n",
    "print(f\"Saved map to unfair_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c156c42b-995e-441a-ad2d-1481ebeeafad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total precincts: 6361\n",
      "Precincts assigned to a new district: 2947\n",
      "Your map is 46.33% different from the 2022 map.\n"
     ]
    }
   ],
   "source": [
    "# --- Code to check \"percent different\" ---\n",
    "\n",
    "# 1. Load the original 2022 map (this was loaded in your notebook)\n",
    "# Make sure the variable 'nj_current_assignment' is still in memory\n",
    "original_map = nj_current_assignment[['GEOID20', 'District']]\n",
    "original_map = original_map.rename(columns={'District': 'District_Original'})\n",
    "\n",
    "# 2. Load your new map\n",
    "new_map = pd.read_csv('unfair_map.csv')\n",
    "new_map = new_map[['GEOID20', 'District']]\n",
    "new_map = new_map.rename(columns={'District': 'District_New'})\n",
    "\n",
    "# 3. Merge them together on the precinct ID\n",
    "comparison_df = pd.merge(original_map, new_map, on='GEOID20')\n",
    "\n",
    "# 4. Count how many precincts are in a different district\n",
    "different_precincts = (comparison_df['District_Original'] != comparison_df['District_New']).sum()\n",
    "\n",
    "# 5. Get the total number of precincts\n",
    "total_precincts = len(comparison_df)\n",
    "\n",
    "# 6. Calculate the percentage\n",
    "percent_different = (different_precincts / total_precincts) * 100\n",
    "\n",
    "print(f\"Total precincts: {total_precincts}\")\n",
    "print(f\"Precincts assigned to a new district: {different_precincts}\")\n",
    "print(f\"Your map is {percent_different:.2f}% different from the 2022 map.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f96bb2-caf9-4b10-a022-2dc2ecaf2423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
