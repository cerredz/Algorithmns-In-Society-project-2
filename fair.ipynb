{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0c8991",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d053be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9044994",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a92056",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel $\\rightarrow$ Restart) and then **run all cells** (in the menubar, select Cell $\\rightarrow$ Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c0d7e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58a3d493-83fb-4965-bdcb-f1054425e86e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geojson in c:\\users\\422mi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shapely in c:\\users\\422mi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\422mi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from shapely) (2.2.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyShp in c:\\users\\422mi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.2.post1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\422mi\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install geojson\n",
    "!pip install shapely\n",
    "!pip install PyShp\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a7f250-1f24-4f02-832b-1df2dceaa50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import csv\n",
    "import ast\n",
    "import shapefile as shp\n",
    "from shapely.geometry import Polygon,shape,MultiPolygon\n",
    "import shapely.ops\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1549e7-0856-443a-aedc-df06d9caf33a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad28b0c5-f5b6-4baf-9295-07dbff55df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDistrictContiguous(district_num, assignment, contiguity_list, print_isolates=False, ignore_list=[]):\n",
    "    ## input:\n",
    "    ## district_num: the district number\n",
    "    ## assignment: the assignment from precinct to district\n",
    "    ## contiguity_list: the list of neighbors for each precinct, from the csv file\n",
    "    contiguity_list.columns = ['Precinct','Neighbors']\n",
    "    district_graph = nx.Graph() #creates an empty undirected graph\n",
    "    district_nodes = assignment[assignment['District']==district_num]['GEOID20'].tolist()\n",
    "    for i in ignore_list:\n",
    "        try:\n",
    "            district_nodes.remove(i)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    district_graph.add_nodes_from(district_nodes)\n",
    "    for id in district_nodes:\n",
    "        neighbors = ast.literal_eval(contiguity_list[contiguity_list['Precinct']==id]['Neighbors'].values.tolist()[0])\n",
    "        # needed to convert string to list because the csv encodes the list as a string\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in district_nodes:\n",
    "                district_graph.add_edge(id,neighbor)\n",
    "    if(print_isolates):\n",
    "        print(list(nx.isolates(district_graph)))\n",
    "    return nx.is_connected(district_graph)\n",
    "\n",
    "\n",
    "def get_cut_edges(current_map_dict, adj_list_dict):\n",
    "    cut_edges = 0\n",
    "    for precinct, neighbors in adj_list_dict.items():\n",
    "        current_district = current_map_dict[precinct]\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in current_map_dict and current_map_dict[neighbor] != current_district:\n",
    "                cut_edges += 1\n",
    "    return cut_edges / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "474da28a-35a4-4115-b19e-9439d1044e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictPopulations(assignment,data_file, num_district):\n",
    "    population = {}\n",
    "    for i in range (1,num_district+1):\n",
    "        population[i] = data_file[data_file['GEOID20'].isin(assignment[assignment['District']==i]['GEOID20'])]['Total_2020_Total'].sum()\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92c27697-04a7-4169-843b-ce2d98622efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistrictShape(district_id, assignment, boundaries):\n",
    "    list_precincts = assignment[assignment['District']==district_id]['GEOID20']\n",
    "    precinct_shapes = []\n",
    "    for i in list_precincts:\n",
    "        if shape(boundaries[i]).geom_type == 'Polygon':\n",
    "            precinct_shapes.append(Polygon(shape(boundaries[i])))\n",
    "        elif shape(boundaries[i]).geom_type == 'MultiPolygon':\n",
    "            precinct_shapes.append(MultiPolygon(shape(boundaries[i])))      \n",
    "    district_shape = shapely.ops.unary_union(precinct_shapes)\n",
    "    #print(district_shape)\n",
    "    return district_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e8260f-2f6a-497e-8ff6-51dd9a767180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_compactness(geom): # Polsby-Popper\n",
    "    p = geom.length\n",
    "    a = geom.area    \n",
    "    return (4*np.pi*a)/(p*p)\n",
    "\n",
    "def box_reock_compactness(geom): # Reock on a rectangle bounding box\n",
    "    a = geom.area \n",
    "    bb = geom.bounds # bounds gives you the minimum bounding box (rectangle)\n",
    "    bba = abs(bb[0]-bb[2])*abs(bb[1]-bb[3])\n",
    "    return a/bba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959227a9-93f8-47fa-87ef-02037facafb9",
   "metadata": {},
   "source": [
    "# This Notebook will help you get started on NJ\n",
    "The data is in Canvas, you should upload it to your Google Drive first (if using Colab), or local filesystem (if using Jupyter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69143d08-629d-436a-8687-7a5d3bcb5aa3",
   "metadata": {},
   "source": [
    "### This is the current assignment of precinct to congressional districts (12 of them for NJ)\n",
    "Note that the map shown in DRA is slightly different. This is because some precincts are split in the real assignment, and some additional precinct are created to handle special situations such as prisoners and overseas citizens. You can ignore this for the class project and just use the data and functions provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c0c2b03-9b2f-46c5-b619-0709ca555c8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Map_Data/precinct-assignments-congress-nj.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nj_current_assignment \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMap_Data/precinct-assignments-congress-nj.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m nj_current_assignment\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\422mi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Map_Data/precinct-assignments-congress-nj.csv'"
     ]
    }
   ],
   "source": [
    "nj_current_assignment = pd.read_csv('Map_Data/precinct-assignments-congress-nj.csv')\n",
    "nj_current_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6bce06-2f20-4f82-959e-a95f91e25ba5",
   "metadata": {},
   "source": [
    "### This is the current demographic and voter data\n",
    "The data has a lot of attributes that lists voters of different demographics and parties in different elections. You can look at the data Dictionary on Canvas to get details. For this recitation we will only keep votes from the 2020  presidential election and the total 2020 population counts. You can use additional columns (e.g., Governor's elections results, voting age (VAP) population counts, or the composite Dem/Rep score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13a23f-3b65-4852-a42d-3a87867f3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID20</th>\n",
       "      <th>District</th>\n",
       "      <th>Total_2020_Pres</th>\n",
       "      <th>Dem_2020_Pres</th>\n",
       "      <th>Rep_2020_Pres</th>\n",
       "      <th>Total_2020_Total</th>\n",
       "      <th>White_2020_Total</th>\n",
       "      <th>Hispanic_2020_Total</th>\n",
       "      <th>Black_2020_Total</th>\n",
       "      <th>Asian_2020_Total</th>\n",
       "      <th>Native_2020_Total</th>\n",
       "      <th>Pacific_2020_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34001005101</td>\n",
       "      <td>2</td>\n",
       "      <td>876</td>\n",
       "      <td>393</td>\n",
       "      <td>472</td>\n",
       "      <td>1240</td>\n",
       "      <td>946</td>\n",
       "      <td>128</td>\n",
       "      <td>102</td>\n",
       "      <td>66</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34001005102</td>\n",
       "      <td>2</td>\n",
       "      <td>852</td>\n",
       "      <td>450</td>\n",
       "      <td>388</td>\n",
       "      <td>1913</td>\n",
       "      <td>1331</td>\n",
       "      <td>211</td>\n",
       "      <td>286</td>\n",
       "      <td>84</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34001005103</td>\n",
       "      <td>2</td>\n",
       "      <td>1206</td>\n",
       "      <td>517</td>\n",
       "      <td>672</td>\n",
       "      <td>1760</td>\n",
       "      <td>1375</td>\n",
       "      <td>177</td>\n",
       "      <td>78</td>\n",
       "      <td>106</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34001005201</td>\n",
       "      <td>2</td>\n",
       "      <td>828</td>\n",
       "      <td>348</td>\n",
       "      <td>469</td>\n",
       "      <td>1311</td>\n",
       "      <td>906</td>\n",
       "      <td>168</td>\n",
       "      <td>150</td>\n",
       "      <td>64</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34001005202</td>\n",
       "      <td>2</td>\n",
       "      <td>868</td>\n",
       "      <td>579</td>\n",
       "      <td>282</td>\n",
       "      <td>1892</td>\n",
       "      <td>537</td>\n",
       "      <td>336</td>\n",
       "      <td>598</td>\n",
       "      <td>450</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>34041115002</td>\n",
       "      <td>7</td>\n",
       "      <td>606</td>\n",
       "      <td>182</td>\n",
       "      <td>418</td>\n",
       "      <td>737</td>\n",
       "      <td>714</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>34041115003</td>\n",
       "      <td>7</td>\n",
       "      <td>617</td>\n",
       "      <td>187</td>\n",
       "      <td>418</td>\n",
       "      <td>934</td>\n",
       "      <td>820</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6358</th>\n",
       "      <td>34041115004</td>\n",
       "      <td>7</td>\n",
       "      <td>478</td>\n",
       "      <td>160</td>\n",
       "      <td>308</td>\n",
       "      <td>697</td>\n",
       "      <td>602</td>\n",
       "      <td>66</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6359</th>\n",
       "      <td>34041115005</td>\n",
       "      <td>7</td>\n",
       "      <td>592</td>\n",
       "      <td>201</td>\n",
       "      <td>381</td>\n",
       "      <td>930</td>\n",
       "      <td>831</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6360</th>\n",
       "      <td>34041115006</td>\n",
       "      <td>7</td>\n",
       "      <td>464</td>\n",
       "      <td>138</td>\n",
       "      <td>319</td>\n",
       "      <td>777</td>\n",
       "      <td>699</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6361 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GEOID20  District  Total_2020_Pres  Dem_2020_Pres  Rep_2020_Pres  \\\n",
       "0     34001005101         2              876            393            472   \n",
       "1     34001005102         2              852            450            388   \n",
       "2     34001005103         2             1206            517            672   \n",
       "3     34001005201         2              828            348            469   \n",
       "4     34001005202         2              868            579            282   \n",
       "...           ...       ...              ...            ...            ...   \n",
       "6356  34041115002         7              606            182            418   \n",
       "6357  34041115003         7              617            187            418   \n",
       "6358  34041115004         7              478            160            308   \n",
       "6359  34041115005         7              592            201            381   \n",
       "6360  34041115006         7              464            138            319   \n",
       "\n",
       "      Total_2020_Total  White_2020_Total  Hispanic_2020_Total  \\\n",
       "0                 1240               946                  128   \n",
       "1                 1913              1331                  211   \n",
       "2                 1760              1375                  177   \n",
       "3                 1311               906                  168   \n",
       "4                 1892               537                  336   \n",
       "...                ...               ...                  ...   \n",
       "6356               737               714                   11   \n",
       "6357               934               820                   60   \n",
       "6358               697               602                   66   \n",
       "6359               930               831                   47   \n",
       "6360               777               699                   30   \n",
       "\n",
       "      Black_2020_Total  Asian_2020_Total  Native_2020_Total  \\\n",
       "0                  102                66                 24   \n",
       "1                  286                84                 38   \n",
       "2                   78               106                 20   \n",
       "3                  150                64                 50   \n",
       "4                  598               450                 25   \n",
       "...                ...               ...                ...   \n",
       "6356                 3                 8                  0   \n",
       "6357                26                10                 14   \n",
       "6358                16                 4                  5   \n",
       "6359                27                11                 12   \n",
       "6360                27                 9                 10   \n",
       "\n",
       "      Pacific_2020_Total  \n",
       "0                      0  \n",
       "1                      4  \n",
       "2                      2  \n",
       "3                      5  \n",
       "4                      1  \n",
       "...                  ...  \n",
       "6356                   0  \n",
       "6357                   0  \n",
       "6358                   0  \n",
       "6359                   0  \n",
       "6360                   0  \n",
       "\n",
       "[6361 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj_precinct_data = pd.read_csv('Map_Data/precinct-data-congress-nj.csv')\n",
    "keepcolumns = ['GEOID20','District','Total_2020_Pres','Dem_2020_Pres','Rep_2020_Pres','Total_2020_Total','White_2020_Total','Hispanic_2020_Total','Black_2020_Total','Asian_2020_Total','Native_2020_Total','Pacific_2020_Total']\n",
    "nj_precinct_data = nj_precinct_data[keepcolumns]\n",
    "nj_precinct_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e75d5-6d29-4ab2-ab58-39c67f8b79f1",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data (uses shapely)\n",
    "\n",
    "This is data that represents the geography of the districts. It is needed to test for contiguity, or for any districting partitioning method based on geography. The data is in Shapely format. Each district is represented as a set of points that are connected to create the district shape (in the long/lat coordinates). Shapely geometric functions can be used to compare the shapes. These can be quite inefficient to run, so I am also providing you a pre-computed index that, for each district, lists the districts that are contiguous to it. You can see the code to generate the index in Contiguity.ipynb.\n",
    "\n",
    "To manipulate the shapes, cast them into Shapely Polygons (see example below) and you can use the Polygon properties and functions: https://shapely.readthedocs.io/en/stable/reference/shapely.Polygon.html#shapely.Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3dbde7-e314-4fe0-9861-969d96e13645",
   "metadata": {},
   "outputs": [],
   "source": [
    "shpfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shp'\n",
    "dbffile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.dbf'\n",
    "shxfile = 'Map_Data/nj_vtd_2020_bound/nj_vtd_2020_bound.shx'\n",
    "\n",
    "\n",
    "shpfile = shp.Reader(shp=shpfile, shx=shxfile, dbf=dbffile)\n",
    "nj_precinct_boundaries={}\n",
    "for sr in shpfile.iterShapeRecords():\n",
    "    geom = sr.shape # get geo bit\n",
    "    rec = sr.record # get db fields\n",
    "    nj_precinct_boundaries[rec[3]]=geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a473b-0936-4c0e-93cc-850329eaa553",
   "metadata": {},
   "source": [
    "### This is the precinct boundary data \n",
    "\n",
    "This use the contiguity index I have pre-computed using Contiguity.ipynb, that is stored in Contiguity_nj.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9f089-caad-45b3-b795-71793bcfedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nj_contiguity = pd.read_csv('Contiguity_nj.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c4cda-bb3c-4392-9df0-5e075c19c27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District 1 True\n",
      "District 2 True\n",
      "District 3 True\n",
      "District 4 True\n",
      "District 5 True\n",
      "District 6 True\n",
      "District 7 True\n",
      "District 8 True\n",
      "District 9 True\n",
      "District 10 True\n",
      "District 11 True\n",
      "District 12 True\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    print(\"District \"+str(i)+\" \"+str(isDistrictContiguous(i, nj_current_assignment, nj_contiguity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bad083-6853-462f-be62-38ff2f84e2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 PP : 0.41768102211569347\n",
      "D1 BR : 0.45075813446417157\n",
      "D2 PP : 0.2632665176502347\n",
      "D2 BR : 0.38278056561756263\n",
      "D3 PP : 0.2280937682959879\n",
      "D3 BR : 0.38134920642809134\n",
      "D4 PP : 0.24812480573284196\n",
      "D4 BR : 0.5390173747196018\n",
      "D5 PP : 0.2410116694999733\n",
      "D5 BR : 0.36320426268176653\n",
      "D6 PP : 0.14677124653853732\n",
      "D6 BR : 0.32853496486220907\n",
      "D7 PP : 0.20246375771704353\n",
      "D7 BR : 0.44049249082841035\n",
      "D8 PP : 0.11227347882175574\n",
      "D8 BR : 0.36670629634952656\n",
      "D9 PP : 0.1683197710884751\n",
      "D9 BR : 0.29705227593212374\n",
      "D10 PP : 0.12061263370064262\n",
      "D10 BR : 0.34528827672774703\n",
      "D11 PP : 0.22236600778446886\n",
      "D11 BR : 0.5557086439792166\n",
      "D12 PP : 0.1620092442171186\n",
      "D12 BR : 0.38520439164401626\n"
     ]
    }
   ],
   "source": [
    "#Compactness of the current assignment\n",
    "for district in range(1,13):\n",
    "    print(\"D\"+str(district)+\" PP : \"+str(pp_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    print(\"D\"+str(district)+\" BR : \"+str(box_reock_compactness(getDistrictShape(district,nj_current_assignment,nj_precinct_boundaries))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f2ef1-b4be-4c73-b87a-f6e9f6e9b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 775340, 2: 778354, 3: 778489, 4: 767834, 5: 774454, 6: 778516, 7: 785173, 8: 800074, 9: 766863, 10: 746178, 11: 769523, 12: 768196}\n"
     ]
    }
   ],
   "source": [
    "# District Population of the current assignment\n",
    "print(getDistrictPopulations(nj_current_assignment,nj_precinct_data, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f943977-f3a0-41b8-930e-6e26d74092f2",
   "metadata": {},
   "source": [
    "# Now create your own redistricting maps\n",
    "Remember to check for contiguity, and to ensure that the population of the districts are balanced (which is not the case in the example above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fda189-958e-4639-8c9e-78d618ea055c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2417956/2269566849.py:25: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  adj_list[row[0]] = set(ast.literal_eval(row[1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Population: 9288994\n",
      "Target Population per District: 774082.83\n",
      "Data prep complete. Fast dictionaries are built.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. PREP YOUR DATA FOR SPEED ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "# --- Convert existing DataFrames into fast Dictionaries ---\n",
    "# (Assumes 'nj_current_assignment', 'nj_contiguity', 'nj_precinct_data',\n",
    "#  and 'nj_precinct_boundaries' are loaded from the cells above)\n",
    "\n",
    "# Convert the assignment DataFrame to a dictionary: {GEOID: District}\n",
    "# This is your main \"map\" object\n",
    "current_map = pd.Series(\n",
    "    nj_current_assignment['District'].values, \n",
    "    index=nj_current_assignment['GEOID20']\n",
    ").to_dict()\n",
    "\n",
    "# Convert contiguity DataFrame to a dictionary: {GEOID: {Neighbor1, Neighbor2, ...}}\n",
    "adj_list = {}\n",
    "for index, row in nj_contiguity.iterrows():\n",
    "    # row[0] is the Precinct GEOID, row[1] is the string-list of neighbors\n",
    "    adj_list[row[0]] = set(ast.literal_eval(row[1]))\n",
    "\n",
    "# Convert precinct data DataFrame to a dictionary: {GEOID: {col: val, ...}}\n",
    "precinct_data = nj_precinct_data.set_index('GEOID20').to_dict('index')\n",
    "\n",
    "# Store the shapefile boundaries (already loaded)\n",
    "boundaries = nj_precinct_boundaries\n",
    "\n",
    "# --- Calculate Population Targets ---\n",
    "total_pop = nj_precinct_data['Total_2020_Total'].sum()\n",
    "target_pop = total_pop / 12\n",
    "print(f\"Total Population: {total_pop}\")\n",
    "print(f\"Target Population per District: {target_pop:.2f}\")\n",
    "\n",
    "# --- Keep copies of the original DataFrames for the GIVEN helper functions ---\n",
    "# We need these *once* to get the initial population\n",
    "nj_precinct_data_df = nj_precinct_data.copy()\n",
    "nj_contiguity_df = nj_contiguity.copy()\n",
    "\n",
    "print(\"Data prep complete. Fast dictionaries are built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d65247-a691-4305-a09c-2904846c5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast helper functions are defined.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. YOUR NEW, FAST HELPER FUNCTIONS ---\n",
    "\n",
    "# Finds all precincts on the border of two different districts\n",
    "def get_border_precincts(current_map_dict, adj_list_dict):\n",
    "    border_precincts = []\n",
    "    for precinct_id, district_id in current_map_dict.items():\n",
    "        my_district = district_id\n",
    "        # Use .get() for safety, in case a precinct has no neighbors\n",
    "        for neighbor_id in adj_list_dict.get(precinct_id, set()):\n",
    "            # Check if neighbor is in the map\n",
    "            if neighbor_id in current_map_dict:\n",
    "                # If a neighbor is in a DIFFERENT district, this is a border precinct\n",
    "                if current_map_dict[neighbor_id] != my_district:\n",
    "                    border_precincts.append(precinct_id)\n",
    "                    break # Stop checking neighbors, we know it's a border\n",
    "    return border_precincts\n",
    "\n",
    "# A blazing-fast population check that just reads a 12-item dictionary\n",
    "def check_balance_from_dict(district_pops, target_pop, tolerance=0.05):\n",
    "    # This tolerance (0.05 = 5%) is from the assignment\n",
    "    for pop in district_pops.values():\n",
    "        if not (target_pop * (1 - tolerance) < pop < target_pop * (1 + tolerance)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# A helper to get vote totals for one district\n",
    "def get_district_vote_totals(district_id, current_map_dict, precinct_data_dict):\n",
    "    dem_votes = 0\n",
    "    rep_votes = 0\n",
    "    for precinct_id, d_id in current_map_dict.items():\n",
    "        if d_id == district_id:\n",
    "            dem_votes += precinct_data_dict[precinct_id].get('Dem_2020_Pres', 0)\n",
    "            rep_votes += precinct_data_dict[precinct_id].get('Rep_2020_Pres', 0)\n",
    "    return dem_votes, rep_votes\n",
    "\n",
    "# Helper to get the total number of seats won\n",
    "def get_total_seats(current_map_dict, precinct_data_dict):\n",
    "    total_seats_won = 0\n",
    "    # Assumes districts are 1-12\n",
    "    for i in range(1, 13):\n",
    "        dem_votes, rep_votes = get_district_vote_totals(i, current_map_dict, precinct_data_dict)\n",
    "        if dem_votes > rep_votes:\n",
    "            total_seats_won += 1\n",
    "    return total_seats_won\n",
    "\n",
    "# A new, FAST contiguity check that uses our dictionaries\n",
    "def is_contiguous_fast(district_id, current_map_dict, adj_list_dict):\n",
    "    # Find all precincts in this district\n",
    "    nodes_in_district = [\n",
    "        precinct_id for precinct_id, d_id in current_map_dict.items() \n",
    "        if d_id == district_id\n",
    "    ]\n",
    "    if not nodes_in_district:\n",
    "        return True # An empty district is \"contiguous\"\n",
    "\n",
    "    # Build a graph *only* for these nodes\n",
    "    district_graph = nx.Graph()\n",
    "    district_graph.add_nodes_from(nodes_in_district)\n",
    "    \n",
    "    start_node = nodes_in_district[0] # Pick one node to start traversal\n",
    "    \n",
    "    for precinct_id in nodes_in_district:\n",
    "        # Look at neighbors (fast lookup)\n",
    "        for neighbor in adj_list_dict.get(precinct_id, set()):\n",
    "            # If the neighbor is ALSO in the district, add an edge\n",
    "            if neighbor in current_map_dict and current_map_dict[neighbor] == district_id:\n",
    "                district_graph.add_edge(precinct_id, neighbor)\n",
    "                \n",
    "    # Check if the graph is connected\n",
    "    return nx.is_connected(district_graph)\n",
    "\n",
    "print(\"Fast helper functions are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c920d-4d66-41af-9eff-64a21f2413ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting UNFAIR optimization. Initial Score: 10000.0001 (10 seats)\n",
      "Iteration 5000, Score: 10000.000040918121 (10 seats)\n",
      "Iteration 10000, Score: 10000.000038221708 (10 seats)\n",
      "Iteration 15000, Score: 10000.000039455575 (10 seats)\n",
      "Iteration 20000, Score: 10000.000037376127 (10 seats)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. THE FINAL OPTIMIZED LOOP (FAIR MAP - COMPACTNESS) ---\n",
    "\n",
    "# --- 1. SETUP ---\n",
    "map_to_optimize = current_map.copy()\n",
    "\n",
    "# Get initial population state\n",
    "df_map_for_pop = pd.DataFrame(map_to_optimize.items(), columns=['GEOID20', 'District'])\n",
    "district_populations = getDistrictPopulations(df_map_for_pop, nj_precinct_data_df, 12)\n",
    "\n",
    "current_cut_edges = get_cut_edges(map_to_optimize, adj_list)\n",
    "\n",
    "# Since the logic below seeks a HIGHER score, we make the score negative.\n",
    "# We weight compactness heavily (x10) vs population balance.\n",
    "current_pop_score = 1.0 / np.std(list(district_populations.values()))\n",
    "current_score = (-1 * current_cut_edges * 10) + current_pop_score\n",
    "\n",
    "print(f\"Starting FAIR optimization. Initial Cut Edges: {current_cut_edges} (Score: {current_score})\")\n",
    "\n",
    "# --- 2. MAIN LOOP ---\n",
    "ITERATIONS = 50000 \n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    if i % 5000 == 0 and i > 0:\n",
    "        print(f\"Iteration {i}, Cut Edges: {current_cut_edges}, Score: {current_score}\")\n",
    "\n",
    "    # 1. Get a random precinct to flip (Same as before)\n",
    "    border_precincts = get_border_precincts(map_to_optimize, adj_list)\n",
    "    if not border_precincts: continue\n",
    "    precinct_to_flip = random.choice(border_precincts)\n",
    "    old_district = map_to_optimize[precinct_to_flip]\n",
    "    \n",
    "    # 2. Find a valid district to flip into (Same as before)\n",
    "    possible_new_districts = []\n",
    "    for neighbor in adj_list[precinct_to_flip]:\n",
    "        if neighbor in map_to_optimize and map_to_optimize[neighbor] != old_district:\n",
    "            possible_new_districts.append(map_to_optimize[neighbor])\n",
    "    if not possible_new_districts: continue\n",
    "    new_district = random.choice(possible_new_districts)\n",
    "\n",
    "    # --- 3. UPDATE STATE (Same as before) ---\n",
    "    pop_to_move = precinct_data[precinct_to_flip]['Total_2020_Total']\n",
    "    district_populations[old_district] -= pop_to_move\n",
    "    district_populations[new_district] += pop_to_move\n",
    "    map_to_optimize[precinct_to_flip] = new_district\n",
    "    \n",
    "    constraints_met = (\n",
    "        check_balance_from_dict(district_populations, target_pop) and\n",
    "        is_contiguous_fast(old_district, map_to_optimize, adj_list) and\n",
    "        is_contiguous_fast(new_district, map_to_optimize, adj_list)\n",
    "    )\n",
    "\n",
    "    # --- 4. EVALUATE THE MOVE (CHANGED) ---\n",
    "    if constraints_met:\n",
    "        # Calculate new compactness\n",
    "        new_cut_edges = get_cut_edges(map_to_optimize, adj_list)\n",
    "        new_pop_score = 1.0 / np.std(list(district_populations.values()))\n",
    "        \n",
    "        # NEW SCORING FORMULA\n",
    "        new_score = (-1 * new_cut_edges * 10) + new_pop_score\n",
    "\n",
    "        # Simulated Annealing Logic\n",
    "        move_kept = False\n",
    "        if new_score > current_score:\n",
    "            move_kept = True \n",
    "        else:\n",
    "            # Temperature calculation\n",
    "            temperature = 1.0 / (i + 1) \n",
    "            # We scale the difference to avoid overflow errors in exp\n",
    "            diff = new_score - current_score\n",
    "            try:\n",
    "                acceptance_prob = math.exp(diff / temperature)\n",
    "            except OverflowError:\n",
    "                acceptance_prob = 0\n",
    "            \n",
    "            if random.random() < acceptance_prob:\n",
    "                move_kept = True\n",
    "\n",
    "        if move_kept:\n",
    "            current_score = new_score\n",
    "            current_cut_edges = new_cut_edges\n",
    "        else:\n",
    "            # Revert\n",
    "            map_to_optimize[precinct_to_flip] = old_district\n",
    "            district_populations[old_district] += pop_to_move\n",
    "            district_populations[new_district] -= pop_to_move\n",
    "            \n",
    "    else:\n",
    "        # Revert\n",
    "        map_to_optimize[precinct_to_flip] = old_district\n",
    "        district_populations[old_district] += pop_to_move\n",
    "        district_populations[new_district] -= pop_to_move\n",
    "\n",
    "# --- 5. FINISH ---\n",
    "print(f\"Optimization Complete! Final Cut Edges: {current_cut_edges}\")\n",
    "\n",
    "final_map_df = pd.DataFrame(map_to_optimize.items(), columns=['GEOID20', 'District'])\n",
    "final_map_df.to_csv('fair_map.csv', index=False)\n",
    "print(f\"Saved map to fair_map.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c156c42b-995e-441a-ad2d-1481ebeeafad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nj_current_assignment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Code to check \"percent different\" ---\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 1. Load the original 2022 map (this was loaded in your notebook)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make sure the variable 'nj_current_assignment' is still in memory\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m original_map \u001b[38;5;241m=\u001b[39m \u001b[43mnj_current_assignment\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGEOID20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      6\u001b[0m original_map \u001b[38;5;241m=\u001b[39m original_map\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict_Original\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# 2. Load your new map\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nj_current_assignment' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Code to check \"percent different\" ---\n",
    "\n",
    "# 1. Load the original 2022 map (this was loaded in your notebook)\n",
    "# Make sure the variable 'nj_current_assignment' is still in memory\n",
    "original_map = nj_current_assignment[['GEOID20', 'District']]\n",
    "original_map = original_map.rename(columns={'District': 'District_Original'})\n",
    "\n",
    "# 2. Load your new map\n",
    "new_map = pd.read_csv('unfair_map.csv')\n",
    "new_map = new_map[['GEOID20', 'District']]\n",
    "new_map = new_map.rename(columns={'District': 'District_New'})\n",
    "\n",
    "# 3. Merge them together on the precinct ID\n",
    "comparison_df = pd.merge(original_map, new_map, on='GEOID20')\n",
    "\n",
    "# 4. Count how many precincts are in a different district\n",
    "different_precincts = (comparison_df['District_Original'] != comparison_df['District_New']).sum()\n",
    "\n",
    "# 5. Get the total number of precincts\n",
    "total_precincts = len(comparison_df)\n",
    "\n",
    "# 6. Calculate the percentage\n",
    "percent_different = (different_precincts / total_precincts) * 100\n",
    "\n",
    "print(f\"Total precincts: {total_precincts}\")\n",
    "print(f\"Precincts assigned to a new district: {different_precincts}\")\n",
    "print(f\"Your map is {percent_different:.2f}% different from the 2022 map.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f96bb2-caf9-4b10-a022-2dc2ecaf2423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
